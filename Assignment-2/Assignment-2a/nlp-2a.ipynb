{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf3169f",
   "metadata": {},
   "source": [
    "# NLP-Various Implementations | Word Embeddings Similarities & Analogies\n",
    "\n",
    "**Overview:** In this part of the project, I implemented an algorithm that identifies similarities between words and predicts missing words in analogies, using the pre-trained word embeddings Word2vec and GloVe. For this purpose, I defined a function that finds the n most similar words for some user-defined input list of words, along with their scores. I also included a function that shows the common words between the two models for each word in that input list. Finally, the code calls the implemented functions with different input parameters to retrieve similar and common words for various words and analogies.\n",
    "\n",
    "## 1. Import all the necessary modules\n",
    "\n",
    "**Briefly:** `gensim.downloader` library gives access to pre-trained word embeddings, whereas `PrettyTable` library provides a way to display data in a table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8b378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2904fe01",
   "metadata": {},
   "source": [
    "## 2. Load pre-trained word embeddings\n",
    "\n",
    "The function load_embeddings() uses the gensim library to load pre-trained word embeddings for two popular models: word2vec-google-news-300 and glove-wiki-gigaword-300. The function returns a tuple containing the loaded embeddings for both models. These embeddings are then assigned to variables named w2v_model and glove_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a08fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings():\n",
    "    return api.load(\"word2vec-google-news-300\"), api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "w2v_model, glove_model = load_embeddings() # loads the pre-trained word embeddings for word2vec and GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb93aa",
   "metadata": {},
   "source": [
    "## 3. Find and compare similar words using word2vec and GloVe embeddings\n",
    "\n",
    "### 3.1. Top-10 similar words for given targets: {car, jaguar, Jaguar, facebook}\n",
    "\n",
    "**Find similar words:** The function get_similar_words takes pre-trained word embedding models along with some input words, and performs similarity search to return the top-N similar words to the input words:\n",
    "\n",
    "* **Step.1:** the function takes several inputs such as: n that determines the number of similar words to be retrieved, models a dictionary of pre-trained word embedding models that will be used to find the similar words, data a list of target words for which the similar words will be retrieved, pos a list of positive context words used in the word embedding models, neg a list of negative context words used in the word embedding models and analogy a boolean value that determines whether the word similarity task is an analogy task or not (simple similarity task).\n",
    "* **Step.2:** the function initializes an empty list sims to store the retrieved similar words. It then iterates over the pre-trained models and for each model, it retrieves the most similar words for each target word and stores them in a table format. It adds the retrieved similar words to sims and prints the table for each model.\n",
    "* **Step.3:** finally, it returns sims which contains the list of similar words for each target word.\n",
    "\n",
    "> The `extra` variable is used to determine whether the word similarity task is an analogy task or a simple similarity task. If analogy is True, then extra is set to an empty list, meaning that no additional context words are used to retrieve similar words. If analogy is False, then extra is set to a list containing one element, which is the current target word d. This is done to enable the model to retrieve similar words based on the current target word and the additional context words provided in pos and neg.\n",
    "\n",
    "The get_similar_words() function is called with several input arguments: value 10, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find similar words, a list of target words including 'car', 'jaguar', 'Jaguar', and 'facebook' to search for similar words within the models, empty lists for the positive and negative words that define the context and an argument 'False' which indicates that it should not generate missing words in analogies. The output of the function is stored in the variable sims, which contains a list of similar words for each target word in the input list.\n",
    "\n",
    "> An empty list is provided for both the `positive` and `negative` context words, indicating that the function should only retrieve similar words based on the target words themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f19052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+----------------------+-------------------------+------------------------+--------------------------+\n",
      "| \u001b[1mcar\u001b[0m                  | \u001b[1mjaguar\u001b[0m                  | \u001b[1mJaguar\u001b[0m                 | \u001b[1mfacebook\u001b[0m                 |\n",
      "+----------------------+-------------------------+------------------------+--------------------------+\n",
      "| vehicle: 0.7821      | jaguars: 0.6738         | Land_Rover: 0.6484     | Facebook: 0.7564         |\n",
      "| cars: 0.7424         | Macho_B: 0.6313         | Aston_Martin: 0.6437   | FaceBook: 0.7077         |\n",
      "| SUV: 0.7161          | panther: 0.6086         | Mercedes: 0.6420       | twitter: 0.6989          |\n",
      "| minivan: 0.6907      | lynx: 0.5815            | Porsche: 0.6233        | myspace: 0.6942          |\n",
      "| truck: 0.6736        | rhino: 0.5754           | BMW: 0.6055            | Twitter: 0.6642          |\n",
      "| Car: 0.6678          | lizard: 0.5607          | Bentley_Arnage: 0.6040 | twitter_facebook: 0.6572 |\n",
      "| Ford_Focus: 0.6673   | tapir: 0.5563           | XF_sedan: 0.5996       | Facebook.com: 0.6530     |\n",
      "| Honda_Civic: 0.6627  | tiger: 0.5529           | Audi: 0.5976           | myspace_facebook: 0.6371 |\n",
      "| Jeep: 0.6511         | leopard: 0.5473         | Jaguar_XF: 0.5951      | facebook_twitter: 0.6368 |\n",
      "| pickup_truck: 0.6441 | Florida_panther: 0.5464 | XJ_saloon: 0.5942      | linkedin: 0.6357         |\n",
      "+----------------------+-------------------------+------------------------+--------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+--------------------+------------------+--------+--------------------+\n",
      "| \u001b[1mcar\u001b[0m                | \u001b[1mjaguar\u001b[0m           | \u001b[1mJaguar\u001b[0m | \u001b[1mfacebook\u001b[0m           |\n",
      "+--------------------+------------------+--------+--------------------+\n",
      "| cars: 0.7827       | rover: 0.5931    | N/A    | twitter: 0.8350    |\n",
      "| vehicle: 0.7655    | bmw: 0.5415      | N/A    | myspace: 0.8056    |\n",
      "| truck: 0.7351      | mercedes: 0.5256 | N/A    | youtube: 0.7292    |\n",
      "| driver: 0.7115     | sepecat: 0.5030  | N/A    | blog: 0.6404       |\n",
      "| driving: 0.6442    | mustang: 0.4987  | N/A    | linkedin: 0.6333   |\n",
      "| vehicles: 0.6328   | lexus: 0.4845    | N/A    | google: 0.6268     |\n",
      "| motorcycle: 0.6023 | volvo: 0.4829    | N/A    | website: 0.6157    |\n",
      "| automobile: 0.5956 | cosworth: 0.4809 | N/A    | web: 0.6143        |\n",
      "| parked: 0.5910     | xk: 0.4764       | N/A    | blogs: 0.6064      |\n",
      "| drivers: 0.5778    | maserati: 0.4757 | N/A    | networking: 0.6047 |\n",
      "+--------------------+------------------+--------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "def get_similar_words(n, models, data, pos, neg, analogy):\n",
    "    sims = []\n",
    "    for model_name, model in models.items():\n",
    "        temp = []\n",
    "        pt = PrettyTable(field_names=[f\"\\033[1m{d}\\033[0m\" for d in data])\n",
    "        for d in data:\n",
    "            extra = [] if analogy else [d]\n",
    "            temp.extend([f\"{s[0]}: {s[1]:.4f}\" for s in model.most_similar(positive=pos+extra, negative=neg, topn=n)]) if all(e in model for e in extra) and all(p in model for p in pos) and all(n in model for n in neg) else temp.extend([\"N/A\"] * n)\n",
    "        for i in range(n):\n",
    "            pt.add_row([temp[i + j*n] for j in range(len(data))])\n",
    "        sims.append([elem.split(':')[0].strip() if \":\" in elem else \"N/A\" for elem in temp])\n",
    "        print('\\033[1m' + f\"\\n{model_name} Model:\" + '\\033[0m')\n",
    "        pt.align = 'l'\n",
    "        print(pt)\n",
    "    return sims\n",
    "\n",
    "sims = get_similar_words(10, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['car', 'jaguar', 'Jaguar', 'facebook'], [], [], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035d046",
   "metadata": {},
   "source": [
    "**Find common words:** The function get_common_words takes the number of similar words to be retrieved, the target words, and a list of similar words for each model as inputs, and returns a table that shows the common words in both models for each target word.\n",
    "\n",
    "* **Step.1:** the function takes three inputs: n that specifies the number of similar words to be retrieved, words a list of target words, and sims a list containing the top-N similar words for each target word for both models.\n",
    "* **Step.2:** it initializes an empty list coms to store the common words in both models for each target word. It then iterates over the retrieved similar words for each target word and finds the intersection of the top-N similar words for both models. It adds the common words to coms and creates a table using PrettyTable. The table shows the common words for each target word and highlights the target word in bold.\n",
    "* **Step.3:** it finally prints the table showing the common words in both models for each target word.\n",
    "\n",
    "The function get_common_words() is called with three input arguments: value 10, which represents the number of common words to retrieve for each pair of target words, a list of target words including 'car', 'jaguar', 'Jaguar', and 'facebook', and the variable sims, which contains a list of similar words for each target word obtained from the pre-trained word embeddings models. The function then compares the lists of similar words for each pair of target words and returns a list of common words that appear in the similar word lists for each pair. This list of common words is then sorted and returned as the output of the function.\n",
    "\n",
    "> The `if/else` statement checks if there are any \"N/A\" values in the similarity results for the current group of similar words for both models. If both models return \"N/A\" for a particular group of similar words, it means that there are no similar words found for that particular target word in both models. In this case, an empty list is added to the list of common words (coms) for that target word. Otherwise, if there are similar words found for the target word in both models, the code creates a list of the common words between the two models by taking the intersection of the similar words retrieved from each model, and adds it to coms. The resulting coms list contains the common words between the two models for each target word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f813627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCommon words in both Models:\u001b[0m\n",
      "+---------+--------+--------+----------+\n",
      "| \u001b[1mcar\u001b[0m     | \u001b[1mjaguar\u001b[0m | \u001b[1mJaguar\u001b[0m | \u001b[1mfacebook\u001b[0m |\n",
      "+---------+--------+--------+----------+\n",
      "| truck   |        |        | myspace  |\n",
      "| vehicle |        |        | twitter  |\n",
      "| cars    |        |        | linkedin |\n",
      "+---------+--------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "def get_common_words(n, words, sims):\n",
    "    coms = []\n",
    "    pt = PrettyTable()\n",
    "    for i in range(0, n*len(words), n):\n",
    "        if 'N/A' in sims[0][i:i+n] and 'N/A' in sims[1][i:i+n]:\n",
    "            coms.append([])\n",
    "        else:\n",
    "            coms.append([word for word in set(sims[0][i:i+n]).intersection(set(sims[1][i:i+n]))])\n",
    "    coms = [sublist + [\"\"] * (max(map(len, coms)) - len(sublist)) for sublist in coms]\n",
    "    for i in range(0, n*len(words), n): \n",
    "        pt.add_column(f\"\\033[1m{words[i // n]}\\033[0m\", coms[i // n]) # where current word = words[i // n]\n",
    "    print('\\033[1m' + \"Common words in both Models:\" + '\\033[0m')\n",
    "    pt.align = 'l'\n",
    "    print(pt)\n",
    "\n",
    "get_common_words(10, ['car', 'jaguar', 'Jaguar', 'facebook'], sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5bd75",
   "metadata": {},
   "source": [
    "### 3.2. Top-10 similar words for user-defined targets: {country, crying, Rachmaninoff, espresso}\n",
    "\n",
    "The get_similar_words() function is called with several input arguments: value 10, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find similar words, a list of target words including 'country', 'crying', 'Rachmaninoff', and 'espresso' to search for similar words within the models, empty lists for the positive and negative words that define the context and an argument 'False' which indicates that it should not generate missing words in analogies. The output of the function is stored in the variable sims, which contains a list of similar words for each target word in the input list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36a7148e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+-----------------------+-------------------------------+-----------------------------+-----------------------------+\n",
      "| \u001b[1mcountry\u001b[0m               | \u001b[1mcrying\u001b[0m                        | \u001b[1mRachmaninoff\u001b[0m                | \u001b[1mespresso\u001b[0m                    |\n",
      "+-----------------------+-------------------------------+-----------------------------+-----------------------------+\n",
      "| nation: 0.7243        | sobbing: 0.7246               | Rachmaninov: 0.7945         | cappuccino: 0.6888          |\n",
      "| continent: 0.6131     | bawling: 0.7187               | Liszt: 0.7910               | mocha: 0.6686               |\n",
      "| region: 0.6015        | cried: 0.7152                 | Tchaikovsky: 0.7728         | coffee: 0.6617              |\n",
      "| thecountry: 0.6002    | screaming: 0.7076             | Shostakovich: 0.7641        | latte: 0.6537               |\n",
      "| world: 0.5980         | weeping: 0.6933               | concerto: 0.7544            | caramel_macchiato: 0.6491   |\n",
      "| coun_try: 0.5917      | cries: 0.6776                 | Mendelssohn: 0.7486         | ristretto: 0.6486           |\n",
      "| United_States: 0.5706 | cry: 0.6610                   | Prokofiev: 0.7482           | espressos: 0.6439           |\n",
      "| countrys: 0.5642      | crying_uncontrollably: 0.6249 | Sergei_Rachmaninoff: 0.7417 | macchiato: 0.6428           |\n",
      "| coutnry: 0.5426       | crying_hysterically: 0.6224   | Brahms: 0.7402              | chai_latte: 0.6308          |\n",
      "| counry: 0.5202        | wailing: 0.6122               | Beethoven: 0.7326           | espresso_cappuccino: 0.6281 |\n",
      "+-----------------------+-------------------------------+-----------------------------+-----------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+-------------------+-------------------+--------------+--------------------+\n",
      "| \u001b[1mcountry\u001b[0m           | \u001b[1mcrying\u001b[0m            | \u001b[1mRachmaninoff\u001b[0m | \u001b[1mespresso\u001b[0m           |\n",
      "+-------------------+-------------------+--------------+--------------------+\n",
      "| nation: 0.7681    | screaming: 0.7579 | N/A          | cappuccino: 0.7127 |\n",
      "| countries: 0.6252 | cried: 0.7549     | N/A          | latte: 0.6035      |\n",
      "| already: 0.5617   | sobbing: 0.7378   | N/A          | coffee: 0.5902     |\n",
      "| has: 0.5607       | yelling: 0.7066   | N/A          | chocolate: 0.5249  |\n",
      "| where: 0.5446     | weeping: 0.7062   | N/A          | mocha: 0.5239      |\n",
      "| now: 0.5413       | cries: 0.6477     | N/A          | gelato: 0.5209     |\n",
      "| since: 0.5411     | cry: 0.6474       | N/A          | decaf: 0.5204      |\n",
      "| all: 0.5411       | laughing: 0.6388  | N/A          | brewed: 0.5163     |\n",
      "| once: 0.5408      | screams: 0.6283   | N/A          | sipping: 0.5059    |\n",
      "| continent: 0.5405 | tears: 0.6199     | N/A          | iced: 0.4981       |\n",
      "+-------------------+-------------------+--------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(10, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['country', 'crying', 'Rachmaninoff', 'espresso'], [], [], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dad200",
   "metadata": {},
   "source": [
    "The function get_common_words() is called with three input arguments: value 10, which represents the number of common words to retrieve for each pair of target words, a list of target words including 'country', 'crying', 'Rachmaninoff', and 'espresso', and the variable sims, which contains a list of similar words for each target word obtained from the pre-trained word embeddings models. The function then compares the lists of similar words for each pair of target words and returns a list of common words that appear in the similar word lists for each pair. This list of common words is then sorted and returned as the output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "247ff25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCommon words in both Models:\u001b[0m\n",
      "+-----------+-----------+--------------+------------+\n",
      "| \u001b[1mcountry\u001b[0m   | \u001b[1mcrying\u001b[0m    | \u001b[1mRachmaninoff\u001b[0m | \u001b[1mespresso\u001b[0m   |\n",
      "+-----------+-----------+--------------+------------+\n",
      "| nation    | cry       |              | cappuccino |\n",
      "| continent | sobbing   |              | mocha      |\n",
      "|           | weeping   |              | coffee     |\n",
      "|           | cries     |              | latte      |\n",
      "|           | cried     |              |            |\n",
      "|           | screaming |              |            |\n",
      "+-----------+-----------+--------------+------------+\n"
     ]
    }
   ],
   "source": [
    "get_common_words(10, ['country', 'crying', 'Rachmaninoff', 'espresso'], sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f393bf",
   "metadata": {},
   "source": [
    "## 4. Find and filter similar words by context using word2vec and GloVe embeddings\n",
    "\n",
    "The function get_similar_words() is called with several input arguments: value 10, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find similar words, a list of target words including 'student' to search for similar words within the models, empty lists for the positive and negative words that define the context, and an argument 'False' which indicates that it should not generate missing words in analogies. The output of the function is stored in the variable sims, which contains a list of similar words for the target word 'student'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1418dc5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+------------------------+\n",
      "| \u001b[1mstudent\u001b[0m                |\n",
      "+------------------------+\n",
      "| students: 0.7295       |\n",
      "| Student: 0.6707        |\n",
      "| teacher: 0.6301        |\n",
      "| stu_dent: 0.6241       |\n",
      "| faculty: 0.6087        |\n",
      "| school: 0.6056         |\n",
      "| undergraduate: 0.6020  |\n",
      "| university: 0.6005     |\n",
      "| undergraduates: 0.5756 |\n",
      "| semester: 0.5738       |\n",
      "+------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+-----------------------+\n",
      "| \u001b[1mstudent\u001b[0m               |\n",
      "+-----------------------+\n",
      "| students: 0.7691      |\n",
      "| teacher: 0.6874       |\n",
      "| graduate: 0.6738      |\n",
      "| school: 0.6131        |\n",
      "| college: 0.6090       |\n",
      "| undergraduate: 0.6044 |\n",
      "| faculty: 0.5999       |\n",
      "| university: 0.5971    |\n",
      "| academic: 0.5810      |\n",
      "| campus: 0.5768        |\n",
      "+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(10, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['student'], [], [], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60649abe",
   "metadata": {},
   "source": [
    "The function get_similar_words() is called with several input arguments: a value of 10, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find similar words, a list of target words including 'student' to search for similar words within the models, an empty list for the positive words that define the positive context and the word 'university' in the negative words list, which indicates that similar words to 'student' associated with 'university' should be excluded from the output. The argument 'False' is used to indicate that it should not generate missing words in analogies. The output of the function is stored in the variable sims, which contains a list of similar words for the target word 'student'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2edd503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+-------------------------+\n",
      "| \u001b[1mstudent\u001b[0m                 |\n",
      "+-------------------------+\n",
      "| sixth_grader: 0.4324    |\n",
      "| seventh_grader: 0.4178  |\n",
      "| 8th_grader: 0.4173      |\n",
      "| eighth_grader: 0.4082   |\n",
      "| grader: 0.3971          |\n",
      "| kindergartner: 0.3918   |\n",
      "| kindergartener: 0.3777  |\n",
      "| Kindergartner: 0.3565   |\n",
      "| teen: 0.3470            |\n",
      "| middle_schooler: 0.3384 |\n",
      "+-------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+---------------------+\n",
      "| \u001b[1mstudent\u001b[0m             |\n",
      "+---------------------+\n",
      "| 15-year: 0.3830     |\n",
      "| 16-year: 0.3815     |\n",
      "| 17-year: 0.3785     |\n",
      "| 14-year: 0.3766     |\n",
      "| 13-year-old: 0.3730 |\n",
      "| 14-year-old: 0.3676 |\n",
      "| 9-year: 0.3667      |\n",
      "| 16-year-old: 0.3615 |\n",
      "| 15-year-old: 0.3510 |\n",
      "| 12-year-old: 0.3490 |\n",
      "+---------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(10, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['student'], [], ['university'], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb258e",
   "metadata": {},
   "source": [
    "The function get_similar_words() is called with several input arguments: a value of 10, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find similar words, a list of target words including 'student' to search for similar words within the models, an empty list for the positive words that define the positive context and the words 'elementary', 'middle', and 'high' in the negative words list, which indicates that similar words to 'student' associated with these educational levels should be excluded from the output. The argument 'False' is used to indicate that it should not generate missing words in analogies. The output of the function is stored in the variable sims, which contains a list of similar words for the target word 'student'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbcef244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+-------------------------------------------------------------------------+\n",
      "| \u001b[1mstudent\u001b[0m                                                                 |\n",
      "+-------------------------------------------------------------------------+\n",
      "| ----------_-----------------------------------------------_GS##: 0.3401 |\n",
      "| K.Kahne_###-###: 0.3000                                                 |\n",
      "| Obiter_Dicta: 0.2770                                                    |\n",
      "| Hannsen: 0.2738                                                         |\n",
      "| NewsTrack_Sports: 0.2734                                                |\n",
      "| Ministere: 0.2702                                                       |\n",
      "| Pi_fraternity: 0.2690                                                   |\n",
      "| Mario_Anzuoni_REUTERS: 0.2634                                           |\n",
      "| Pharma_ceutical: 0.2584                                                 |\n",
      "| M.Kenseth_###-###: 0.2571                                               |\n",
      "+-------------------------------------------------------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+------------------------+\n",
      "| \u001b[1mstudent\u001b[0m                |\n",
      "+------------------------+\n",
      "| furre: 0.4075          |\n",
      "| khujo: 0.3997          |\n",
      "| monechma: 0.3992       |\n",
      "| bio-tech: 0.3907       |\n",
      "| farzaneh: 0.3874       |\n",
      "| panÄƒ: 0.3873           |\n",
      "| chanjindamanee: 0.3846 |\n",
      "| tabarzadi: 0.3844      |\n",
      "| pitambar: 0.3830       |\n",
      "| jnm: 0.3828            |\n",
      "+------------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(10, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['student'], [], ['elementary','middle','high'], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e702096",
   "metadata": {},
   "source": [
    "## 5. Solve word analogies using word2vec and GloVe embeddings\n",
    "\n",
    "### 5.1. Top-2 solutions for five given analogies\n",
    "\n",
    "The function get_similar_words() is called with several input arguments: a value of 2, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find the most similar words in an analogy, an analogy represented by a list of target words, which is 'king - man + woman' in this case. The positive words list includes 'king' and 'woman', whereas the negative words list includes the word 'man', which specifies the type of relationship to be captured in the analogy. The argument 'True' is used to indicate that the function should generate missing words in analogies, if any. The output of the function is stored in the variable sims, which contains a list of the two most similar words that fit the analogy according to the Word2vec and GloVe models.\n",
    "\n",
    "> In this analogy, we want to find a word that is related to 'woman' in the same way that 'man' is related to 'king'. To achieve this, we include 'king' and 'woman' in the positive words list. The word 'king' is included because it plays the role of the known component in the relationship we want to capture, while 'woman' represents the unknown component. We exclude 'man' from the list because we want to replace it with the word we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5c7b1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+--------------------+\n",
      "| \u001b[1mking - man + woman\u001b[0m |\n",
      "+--------------------+\n",
      "| queen: 0.7118      |\n",
      "| monarch: 0.6190    |\n",
      "+--------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+--------------------+\n",
      "| \u001b[1mking - man + woman\u001b[0m |\n",
      "+--------------------+\n",
      "| queen: 0.6713      |\n",
      "| princess: 0.5433   |\n",
      "+--------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(2, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['king - man + woman'], ['king','woman'], ['man'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8124fb",
   "metadata": {},
   "source": [
    "**Man is to king as woman is to what?:** In this particular example, the answer to the analogy is `queen`. Both models have correctly identified \"queen\" as the answer to the analogy, with the Word2vec model being slightly more confident in its prediction than the GloVe model. However, both models have reasonably high scores for \"queen\" as the answer, which indicates that they have learned the association between the words \"man-king\" and \"woman-queen\" from the training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e28b0",
   "metadata": {},
   "source": [
    "The function get_similar_words() is called with several input arguments: a value of 2, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find the most similar words in an analogy, an analogy represented by a list of target words, which is 'france - paris + tokyo' in this case. The positive words list includes 'france' and 'tokyo', whereas the negative words list includes the word 'paris', which specifies the type of relationship to be captured in the analogy. The argument 'True' is used to indicate that the function should generate missing words in analogies, if any. The output of the function is stored in the variable sims, which contains a list of the two most similar words that fit the analogy according to the Word2vec and GloVe models.\n",
    "\n",
    "> In this analogy, we want to find a word that is related to 'tokyo' in the same way that 'paris' is related to 'france'. To achieve this, we include 'france' and 'tokyo' in the positive words list. The word 'france' is included because it plays the role of the known component in the relationship we want to capture, while 'tokyo' represents the unknown component. We exclude 'paris' from the list because we want to replace it with the word we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9b59677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+------------------------+\n",
      "| \u001b[1mfrance - paris + tokyo\u001b[0m |\n",
      "+------------------------+\n",
      "| japan: 0.5508          |\n",
      "| hong_kong: 0.5012      |\n",
      "+------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+------------------------+\n",
      "| \u001b[1mfrance - paris + tokyo\u001b[0m |\n",
      "+------------------------+\n",
      "| japan: 0.8017          |\n",
      "| japanese: 0.6111       |\n",
      "+------------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(2, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['france - paris + tokyo'], ['france','tokyo'], ['paris'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c7193",
   "metadata": {},
   "source": [
    "**Paris is to france as tokyo is to what?:** In this particular example, both models have identified `japan` as the answer to the analogy, with the GloVe model being more confident in its prediction than the Word2vec model. The GloVe model has a score of 0.8017 for \"japan\" while the Word2vec model has a score of 0.5508 for the same word. These scores indicate that both models have learned the association between the words \"paris-france\" and \"tokyo-japan\" from the training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f23cc4",
   "metadata": {},
   "source": [
    "The function get_similar_words() is called with several input arguments: a value of 2, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find the most similar words in an analogy, an analogy represented by a list of target words, which is 'trees - apples + grapes' in this case. The positive words list includes 'trees' and 'grapes', whereas the negative words list includes the word 'apples', which specifies the type of relationship to be captured in the analogy. The argument 'True' is used to indicate that the function should generate missing words in analogies, if any. The output of the function is stored in the variable sims, which contains a list of the two most similar words that fit the analogy according to the Word2vec and GloVe models.\n",
    "\n",
    "> In this analogy, we want to find a word that is related to 'grapes' in the same way that 'apples' is related to 'trees'. To achieve this, we include 'trees' and 'grapes' in the positive words list. The word 'trees' is included because it plays the role of the known component in the relationship we want to capture, while 'grapes' represents the unknown component. We exclude 'apples' from the list because we want to replace it with the word we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b69b38f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+-------------------------+\n",
      "| \u001b[1mtrees - apples + grapes\u001b[0m |\n",
      "+-------------------------+\n",
      "| oak_trees: 0.6750       |\n",
      "| vines: 0.6702           |\n",
      "+-------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+-------------------------+\n",
      "| \u001b[1mtrees - apples + grapes\u001b[0m |\n",
      "+-------------------------+\n",
      "| vines: 0.5909           |\n",
      "| tree: 0.5843            |\n",
      "+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(2, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['trees - apples + grapes'], ['trees','grapes'], ['apples'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5aa3c",
   "metadata": {},
   "source": [
    "**Apples is to trees as grapes is to what?:** In this particular example, only the GloVe model has identified `vines` as the answer to the analogy, while the Word2vec model has identified \"oak_trees\" and \"vines\" as potential answers, with slightly higher confidence for \"oak_trees\". However, both models have relatively low scores for their predicted answers, indicating that that both models have learned some kind of association between the words \"apples-trees\" and \"grapes-vines\" from the training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92081338",
   "metadata": {},
   "source": [
    "The function get_similar_words() is called with several input arguments: a value of 2, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find the most similar words in an analogy, an analogy represented by a list of target words, which is 'swimming - walking + walked' in this case. The positive words list includes 'swimming' and 'walked', whereas the negative words list includes the word 'walking', which specifies the type of relationship to be captured in the analogy. The argument 'True' is used to indicate that the function should generate missing words in analogies, if any. The output of the function is stored in the variable sims, which contains a list of the two most similar words that fit the analogy according to the Word2vec and GloVe models.\n",
    "\n",
    "> In this analogy, we want to find a word that is related to 'walked' in the same way that 'walking' is related to 'swimming'. To achieve this, we include 'swimming' and 'walked' in the positive words list. The word 'swimming' is included because it plays the role of the known component in the relationship we want to capture, while 'walked' represents the unknown component. We exclude 'walking' from the list because we want to replace it with the word we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67fd221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+-----------------------------+\n",
      "| \u001b[1mswimming - walking + walked\u001b[0m |\n",
      "+-----------------------------+\n",
      "| swam: 0.6926                |\n",
      "| swim: 0.6725                |\n",
      "+-----------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+-----------------------------+\n",
      "| \u001b[1mswimming - walking + walked\u001b[0m |\n",
      "+-----------------------------+\n",
      "| swam: 0.4978                |\n",
      "| swimmers: 0.4852            |\n",
      "+-----------------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(2, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['swimming - walking + walked'], ['swimming','walked'], ['walking'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5688e676",
   "metadata": {},
   "source": [
    "**Walking is to swimming as walked is to what?:** In this particular example, both models have identified `swam` as the answer to the analogy, with the Word2vec model being more confident in its prediction than the GloVe model. The Word2vec model has a score of 0.6926 for swam, while the GloVe model has a score of 0.4978 for swam. Additionally, both models have reasonably high scores for swim as the answer, which indicates that they have learned the association between the words \"walking-swimming\" and \"walked-swam\" from the training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764154a6",
   "metadata": {},
   "source": [
    "The function get_similar_words() is called with several input arguments: a value of 2, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find the most similar words in an analogy, an analogy represented by a list of target words, which is 'doctor - father + mother' in this case. The positive words list includes 'doctor' and 'mother', whereas the negative words list includes the word 'father', which specifies the type of relationship to be captured in the analogy. The argument 'True' is used to indicate that the function should generate missing words in analogies, if any. The output of the function is stored in the variable sims, which contains a list of the two most similar words that fit the analogy according to the Word2vec and GloVe models.\n",
    "\n",
    "> In this analogy, we want to find a word that is related to 'mother' in the same way that 'father' is related to 'doctor'. To achieve this, we include 'doctor' and 'mother' in the positive words list. The word 'doctor' is included because it plays the role of the known component in the relationship we want to capture, while 'mother' represents the unknown component. We exclude 'father' from the list because we want to replace it with the word we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "045afdfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+--------------------------+\n",
      "| \u001b[1mdoctor - father + mother\u001b[0m |\n",
      "+--------------------------+\n",
      "| nurse: 0.7128            |\n",
      "| doctors: 0.6593          |\n",
      "+--------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+--------------------------+\n",
      "| \u001b[1mdoctor - father + mother\u001b[0m |\n",
      "+--------------------------+\n",
      "| nurse: 0.6570            |\n",
      "| doctors: 0.6172          |\n",
      "+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(2, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['doctor - father + mother'], ['doctor','mother'], ['father'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeffe67b",
   "metadata": {},
   "source": [
    "**Father is to doctor as mother is to what?:** In this particular example, both the Word2vec and GloVe models have unfortunately identified `nurse` as the answer to the analogy. The Word2vec model is slightly more confident in its prediction, with a score of 0.7128 for \"nurse\", while the GloVe model has a score of 0.6570. These high scores for \"nurse\" as the answer indicate that both models have learned the association between the words \"father-doctor\" and \"mother-nurse\" from the training corpus. This association is considered bad because it reinforces gender stereotypes and biases. The analogy implies that fathers are more likely to become doctors and mothers are more likely to become nurses, which is obviously not true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43bf5a",
   "metadata": {},
   "source": [
    "### 5.2. Top-2 solutions for five user-defined analogies\n",
    "\n",
    "The function get_similar_words() is called with several input arguments: a value of 2, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find the most similar words in an analogy, an analogy represented by a list of target words, which is 'russian - pelmeni + dumplings' in this case. The positive words list includes 'russian' and 'dumplings', whereas the negative words list includes the word 'pelmeni', which specifies the type of relationship to be captured in the analogy. The argument 'True' is used to indicate that the function should generate missing words in analogies, if any. The output of the function is stored in the variable sims, which contains a list of the two most similar words that fit the analogy according to the Word2vec and GloVe models.\n",
    "\n",
    "> In this analogy, we want to find a word that is related to 'dumplings' in the same way that 'pelmeni' is related to 'russian'. To achieve this, we include 'russian' and 'dumplings' in the positive words list. The word 'russian' is included because it plays the role of the known component in the relationship we want to capture, while 'dumplings' represents the unknown component. We exclude 'pelmeni' from the list because we want to replace it with the word we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ab766e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+-------------------------------+\n",
      "| \u001b[1mrussian - pelmeni + dumplings\u001b[0m |\n",
      "+-------------------------------+\n",
      "| chinese: 0.5360               |\n",
      "| japanese: 0.5182              |\n",
      "+-------------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+-------------------------------+\n",
      "| \u001b[1mrussian - pelmeni + dumplings\u001b[0m |\n",
      "+-------------------------------+\n",
      "| chinese: 0.5497               |\n",
      "| russia: 0.5305                |\n",
      "+-------------------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(2, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['russian - pelmeni + dumplings'], ['russian','dumplings'], ['pelmeni'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b32119",
   "metadata": {},
   "source": [
    "**Pelmeni is to russian as dumplings is to what?:** In this particular example, both the Word2vec and GloVe models have identified `chinese` as the answer to the analogy. The GloVe model is slightly more confident in its prediction, with a score of 0.5497 for \"chinese\", while the Word2vec model has a score of 0.5360. These high scores for \"chinese\" as the answer indicate that both models have learned the association between the words \"pelmeni-russian\" and \"dumplings-chinese\" from the training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b65550",
   "metadata": {},
   "source": [
    "The function get_similar_words() is called with several input arguments: a value of 2, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find the most similar words in an analogy, an analogy represented by a list of target words, which is 'piano - sonata + symphony' in this case. The positive words list includes 'piano' and 'symphony', whereas the negative words list includes the word 'sonata', which specifies the type of relationship to be captured in the analogy. The argument 'True' is used to indicate that the function should generate missing words in analogies, if any. The output of the function is stored in the variable sims, which contains a list of the two most similar words that fit the analogy according to the Word2vec and GloVe models.\n",
    "\n",
    "> In this analogy, we want to find a word that is related to 'symphony' in the same way that 'sonata' is related to 'piano'. To achieve this, we include 'piano' and 'symphony' in the positive words list. The word 'piano' is included because it plays the role of the known component in the relationship we want to capture, while 'symphony' represents the unknown component. We exclude 'sonata' from the list because we want to replace it with the word we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d238b2ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+----------------------------+\n",
      "| \u001b[1mpiano - sonata + symphony\u001b[0m  |\n",
      "+----------------------------+\n",
      "| orchestra: 0.7010          |\n",
      "| symphony_orchestra: 0.5961 |\n",
      "+----------------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+---------------------------+\n",
      "| \u001b[1mpiano - sonata + symphony\u001b[0m |\n",
      "+---------------------------+\n",
      "| orchestra: 0.7714         |\n",
      "| orchestras: 0.6377        |\n",
      "+---------------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(2, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['piano - sonata + symphony'], ['piano','symphony'], ['sonata'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c593a38e",
   "metadata": {},
   "source": [
    "**Sonata is to piano as symphony is to what?:** In this particular example, both the Word2vec and GloVe models have identified `orchestra` as the answer to the analogy. The Word2vec model has a score of 0.7010 for \"orchestra\", while the GloVe model has a higher score of 0.7714. These high scores for \"orchestra\" as the answer indicate that both models have learned the association between the words \"sonata-piano\" and \"symphony-orchestra\" from the training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b6b183",
   "metadata": {},
   "source": [
    "The function get_similar_words() is called with several input arguments: a value of 2, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find the most similar words in an analogy, an analogy represented by a list of target words, which is 'bad - war + peace' in this case. The positive words list includes 'bad' and 'peace', whereas the negative words list includes the word 'war', which specifies the type of relationship to be captured in the analogy. The argument 'True' is used to indicate that the function should generate missing words in analogies, if any. The output of the function is stored in the variable sims, which contains a list of the two most similar words that fit the analogy according to the Word2vec and GloVe models.\n",
    "\n",
    "> In this analogy, we want to find a word that is related to 'peace' in the same way that 'war' is related to 'bad'. To achieve this, we include 'bad' and 'peace' in the positive words list. The word 'bad' is included because it plays the role of the known component in the relationship we want to capture, while 'peace' represents the unknown component. We exclude 'war' from the list because we want to replace it with the word we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5675b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Word2vec Model:\u001b[0m\n",
      "+-------------------+\n",
      "| \u001b[1mbad - war + peace\u001b[0m |\n",
      "+-------------------+\n",
      "| good: 0.5381      |\n",
      "| Bad: 0.4294       |\n",
      "+-------------------+\n",
      "\u001b[1m\n",
      "GloVe Model:\u001b[0m\n",
      "+-------------------+\n",
      "| \u001b[1mbad - war + peace\u001b[0m |\n",
      "+-------------------+\n",
      "| good: 0.5159      |\n",
      "| things: 0.4778    |\n",
      "+-------------------+\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_words(2, {'Word2vec': w2v_model, 'GloVe': glove_model}, ['bad - war + peace'], ['bad','peace'], ['war'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc93d0da",
   "metadata": {},
   "source": [
    "**War is to bad as peace is to what?:** In this particular example, both the Word2vec and GloVe models have identified `good` as the answer to the analogy. The Word2vec model is slightly more confident in its prediction, with a score of 0.5381 for \"good\", while the GloVe model has a score of 0.5159. These scores indicate that both models have learned the association between the words \"war-bad\" and \"peace-good\" from the training corpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
