{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf3169f",
   "metadata": {},
   "source": [
    "# NLP-Various Implementations | Text Classification using TF-IDF Vectorization\n",
    "\n",
    "**Overview:** In this part of the project, I implemented a machine learning model that classifies text using Naive Bayes and Support Vector Machines (SVM) algorithms. The TfidfVectorizer function transforms text into feature vectors, and the train_classifier() function trains the classifier. The predict() function outputs predicted labels, whereas the run_model() function returns accuracy, dimensionality, time cost, and misclassification data for later use. The analyze_results() function outputs the most common misclassification pair and a random text with corresponding true and predicted labels for each model. The code also provides a way to compare the performance of Naive Bayes and SVM using various parameters.\n",
    "\n",
    "## 1. Import all the necessary modules\n",
    "\n",
    "**Briefly:** `csv` library provides functionality for working with Comma Separated Value (CSV) files, `time` provides functions for working with time-related tasks, `random` provides tools for generating random numbers, `defaultdict` provides a way to create a dictionary with default values for nonexistent keys, `PrettyTable` provides a way to display data in a table format, `TfidfVectorizer` is a function from `sklearn.feature_extraction.text` that transforms text into feature vectors, `MultinomialNB` and `LinearSVC` are machine learning algorithms from `sklearn.naive_bayes` and `sklearn.svm respectively`, used for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8b378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import random\n",
    "from prettytable import PrettyTable\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2904fe01",
   "metadata": {},
   "source": [
    "## 2. Load the training and testing datasets\n",
    "\n",
    "The function load_dataset() takes in the path of a CSV file containing text data and returns a dictionary with the features and labels. The features are a concatenation of the second and third columns of each row in the CSV file, while the labels correspond to the first column. The function is used to load the training and test data from two CSV files in the specified file paths and store them in variables named train_data and test_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a08fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = list(csv.reader(f))\n",
    "    return {\"features\": [row[1] + ' ' + row[2] for row in data[1:]], \"labels\": [row[0] for row in data[1:]]}\n",
    "\n",
    "train_data = load_dataset(\"C:/Users/natalia/pyproj/nlp-proj/assignment-2b/train.csv\")\n",
    "test_data = load_dataset(\"C:/Users/natalia/pyproj/nlp-proj/assignment-2b/test.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb93aa",
   "metadata": {},
   "source": [
    "## 3. Find and compare similar words using word2vec and GloVe embeddings\n",
    "\n",
    "**Find similar words:** The function get_similar_words takes pre-trained word embedding models along with some input words, and performs similarity search to return the top-N similar words to the input words:\n",
    "\n",
    "* **Step.1:** the function takes several inputs such as: n that determines the number of similar words to be retrieved, models a dictionary of pre-trained word embedding models that will be used to find the similar words, data a list of target words for which the similar words will be retrieved, pos a list of positive context words used in the word embedding models, neg a list of negative context words used in the word embedding models and analogy a boolean value that determines whether the word similarity task is an analogy task or not (simple similarity task).\n",
    "* **Step.2:** the function initializes an empty list sims to store the retrieved similar words. It then iterates over the pre-trained models and for each model, it retrieves the most similar words for each target word and stores them in a table format. It adds the retrieved similar words to sims and prints the table for each model.\n",
    "* **Step.3:** finally, it returns sims which contains the list of similar words for each target word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f19052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_model(train_data, test_data, n, approach, classifier):\n",
    "    start = time.time()\n",
    "    X_train, X_test, vocab = extract_features(train_data[\"features\"], test_data[\"features\"], n, approach) # (i, j) entries represent the presence and frequency of the j-th feature (word) in the i-th document - the values in each entry represent the corresponding term frequency-inverse document frequency (tf-idf) score\n",
    "    y_train, y_test = train_data[\"labels\"], test_data[\"labels\"]\n",
    "    clf = train_classifier(X_train, y_train, classifier)\n",
    "    end = time.time()\n",
    "    misclass_data = detect_misclassification(test_data, clf.predict(X_test))\n",
    "    return clf.score(X_test, y_test), len(vocab), end - start, misclass_data\n",
    "\n",
    "def extract_features(train_text, test_text, n, approach):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(n,n), lowercase=True, analyzer=approach) # where (n,n): the lower and upper bounds of the range of n-grams to be extracted\n",
    "    return vectorizer.fit_transform(train_text), vectorizer.transform(test_text), vectorizer.vocabulary_\n",
    "\n",
    "def train_classifier(X_train, y_train, classifier):\n",
    "    return classifier.fit(X_train, y_train)\n",
    "\n",
    "def predict(classifier, X_test):\n",
    "    return classifier.predict(X_test)\n",
    "\n",
    "def detect_misclassification(test_data, y_pred):\n",
    "    misclass_data = defaultdict(list)\n",
    "    for i in range(len(test_data[\"labels\"])):\n",
    "        true_label = test_data[\"labels\"][i]\n",
    "        predicted_label = y_pred[i]\n",
    "        if true_label != predicted_label:\n",
    "            text = test_data[\"features\"][i]\n",
    "            misclass_data[true_label].append((text, predicted_label))\n",
    "    return misclass_data\n",
    "\n",
    "accuracy, dimensionality, time_cost, misclass_data_mnv1w = run_model(train_data, test_data, 1, \"word\", MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035d046",
   "metadata": {},
   "source": [
    "**Find common words:** The function get_common_words takes the number of similar words to be retrieved, the target words, and a list of similar words for each model as inputs, and returns a table that shows the common words in both models for each target word.\n",
    "\n",
    "* **Step.1:** the function takes three inputs: n that specifies the number of similar words to be retrieved, words a list of target words, and sims a list containing the top-N similar words for each target word for both models.\n",
    "* **Step.2:** it initializes an empty list coms to store the common words in both models for each target word. It then iterates over the retrieved similar words for each target word and finds the intersection of the top-N similar words for both models. It adds the common words to coms and creates a table using PrettyTable. The table shows the common words for each target word and highlights the target word in bold.\n",
    "* **Step.3:** it finally prints the table showing the common words in both models for each target word.\n",
    "\n",
    "The function get_common_words() is called with three input arguments: value 10, which represents the number of common words to retrieve for each pair of target words, a list of target words including 'car', 'jaguar', 'Jaguar', and 'facebook', and the variable sims, which contains a list of similar words for each target word obtained from the pre-trained word embeddings models. The function then compares the lists of similar words for each pair of target words and returns a list of common words that appear in the similar word lists for each pair. This list of common words is then sorted and returned as the output of the function.\n",
    "\n",
    "> The `if/else` statement checks if there are any \"N/A\" values in the similarity results for the current group of similar words for both models. If both models return \"N/A\" for a particular group of similar words, it means that there are no similar words found for that particular target word in both models. In this case, an empty list is added to the list of common words (coms) for that target word. Otherwise, if there are similar words found for the target word in both models, the code creates a list of the common words between the two models by taking the intersection of the similar words retrieved from each model, and adds it to coms. The resulting coms list contains the common words between the two models for each target word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f813627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMultinomial Na誰ve Bayes using tf-idf word uni-grams:\u001b[0m\n",
      "+--------------------+----------------+-------------------+\n",
      "|      \u001b[1mAccuracy\u001b[0m      | \u001b[1mDimensionality\u001b[0m |     \u001b[1mTime Cost\u001b[0m     |\n",
      "+--------------------+----------------+-------------------+\n",
      "| 0.9022368421052631 |     64999      | 5.747888565063477 |\n",
      "+--------------------+----------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "def visualize(model, accuracy, dimensionality, time_cost):\n",
    "    print(f\"\\033[1m{model}:\\033[0m\")\n",
    "    pt = PrettyTable(field_names=[f\"\\033[1m{field}\\033[0m\" for field in [\"Accuracy\", \"Dimensionality\", \"Time Cost\"]])\n",
    "    pt.add_row([accuracy, dimensionality, time_cost])\n",
    "    print(pt)\n",
    "\n",
    "visualize(\"Multinomial Na誰ve Bayes using tf-idf word uni-grams\", accuracy, dimensionality, time_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5bd75",
   "metadata": {},
   "source": [
    "### 3.2. Top-10 similar words for user-defined targets: {country, crying, Rachmaninoff, espresso}\n",
    "\n",
    "The get_similar_words() function is called with several input arguments: value 10, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find similar words, a list of target words including 'country', 'crying', 'Rachmaninoff', and 'espresso' to search for similar words within the models, empty lists for the positive and negative words that define the context and an argument 'False' which indicates that it should not generate missing words in analogies. The output of the function is stored in the variable sims, which contains a list of similar words for each target word in the input list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a7148e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMultinomial Na誰ve Bayes using tf-idf character tri-grams:\u001b[0m\n",
      "+--------------------+----------------+--------------------+\n",
      "|      \u001b[1mAccuracy\u001b[0m      | \u001b[1mDimensionality\u001b[0m |     \u001b[1mTime Cost\u001b[0m      |\n",
      "+--------------------+----------------+--------------------+\n",
      "| 0.8686842105263158 |     31074      | 24.929243564605713 |\n",
      "+--------------------+----------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "accuracy, dimensionality, time_cost, misclass_data_mnv3c = run_model(train_data, test_data, 3, \"char\", MultinomialNB())\n",
    "visualize(\"Multinomial Na誰ve Bayes using tf-idf character tri-grams\", accuracy, dimensionality, time_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf403a0",
   "metadata": {},
   "source": [
    "The function get_common_words() is called with three input arguments: value 10, which represents the number of common words to retrieve for each pair of target words, a list of target words including 'country', 'crying', 'Rachmaninoff', and 'espresso', and the variable sims, which contains a list of similar words for each target word obtained from the pre-trained word embeddings models. The function then compares the lists of similar words for each pair of target words and returns a list of common words that appear in the similar word lists for each pair. This list of common words is then sorted and returned as the output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326a7a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSupport Vector Machines using tf-idf word uni-grams:\u001b[0m\n",
      "+--------------------+----------------+--------------------+\n",
      "|      \u001b[1mAccuracy\u001b[0m      | \u001b[1mDimensionality\u001b[0m |     \u001b[1mTime Cost\u001b[0m      |\n",
      "+--------------------+----------------+--------------------+\n",
      "| 0.9196052631578947 |     64999      | 12.181857585906982 |\n",
      "+--------------------+----------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "accuracy, dimensionality, time_cost, misclass_data_svm1w = run_model(train_data, test_data, 1, \"word\", LinearSVC(C=1))\n",
    "visualize(\"Support Vector Machines using tf-idf word uni-grams\", accuracy, dimensionality, time_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f393bf",
   "metadata": {},
   "source": [
    "## 4. Find and filter similar words by context using word2vec and GloVe embeddings\n",
    "\n",
    "The function get_similar_words() is called with several input arguments: value 10, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find similar words, a list of target words including 'student' to search for similar words within the models, empty lists for the positive and negative words that define the context, and an argument 'False' which indicates that it should not generate missing words in analogies. The output of the function is stored in the variable sims, which contains a list of similar words for the target word 'student'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1418dc5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSupport Vector Machines using tf-idf character tri-grams:\u001b[0m\n",
      "+--------------------+----------------+-------------------+\n",
      "|      \u001b[1mAccuracy\u001b[0m      | \u001b[1mDimensionality\u001b[0m |     \u001b[1mTime Cost\u001b[0m     |\n",
      "+--------------------+----------------+-------------------+\n",
      "| 0.9121052631578948 |     31074      | 39.59399223327637 |\n",
      "+--------------------+----------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "accuracy, dimensionality, time_cost, misclass_data_svm3c = run_model(train_data, test_data, 3, \"char\", LinearSVC(C=1))\n",
    "visualize(\"Support Vector Machines using tf-idf character tri-grams\", accuracy, dimensionality, time_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceaea44",
   "metadata": {},
   "source": [
    "The function get_similar_words() is called with several input arguments: a value of 10, which represents the number of similar words to retrieve, a dictionary with two pre-trained word embeddings models, 'Word2vec' and 'GloVe' which are used to find similar words, a list of target words including 'student' to search for similar words within the models, an empty list for the positive words that define the positive context and the word 'university' in the negative words list, which indicates that similar words to 'student' associated with 'university' should be excluded from the output. The argument 'False' is used to indicate that it should not generate missing words in analogies. The output of the function is stored in the variable sims, which contains a list of similar words for the target word 'student'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "973ed8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------------+\n",
      "| \u001b[1mTrue Label\u001b[0m | \u001b[1mMisclassification Times\u001b[0m |\n",
      "+------------+-------------------------+\n",
      "|     4      |            85           |\n",
      "|     3      |           135           |\n",
      "|     1      |           112           |\n",
      "|     2      |            9            |\n",
      "+------------+-------------------------+\n",
      "\u001b[1mMost common Misclassification Pair:\u001b[0m\n",
      "+------------+-----------------+-----------+\n",
      "| \u001b[1mTrue Label\u001b[0m | \u001b[1mPredicted Label\u001b[0m | \u001b[1mFrequency\u001b[0m |\n",
      "+------------+-----------------+-----------+\n",
      "|     3      |        4        |    381    |\n",
      "+------------+-----------------+-----------+\n",
      "\u001b[1mText: \u001b[0mFeds kick off digital TV consumer campaign WASHINGTON - It #39;s one of the biggest technical changes in television since color TV: the digital transition. And because many Americans remain in the dark about it, federal regulators began an education campaign Monday to enlighten them.\u001b[1m\n",
      "True Label: \u001b[0m3\n",
      "+-------+------------+\n",
      "| \u001b[1mModel\u001b[0m | \u001b[1mPrediction\u001b[0m |\n",
      "+-------+------------+\n",
      "| mnv1w |     4      |\n",
      "| mnv3c |     4      |\n",
      "| svm1w |     4      |\n",
      "| svm3c |     4      |\n",
      "+-------+------------+\n"
     ]
    }
   ],
   "source": [
    "def analyze_results(mnv1w, mnv3c, svm1w, svm3c):\n",
    "    \n",
    "    common_misclass_data = defaultdict(list)\n",
    "    for true_label in mnv1w.keys():\n",
    "        for text, label in mnv1w[true_label]:\n",
    "            labels = [label] + [next((p for t, p in model[true_label] if t == text), '') for model in [mnv3c, svm1w, svm3c]]\n",
    "            common_misclass_data[true_label].append((text, labels)) if all(labels) else None\n",
    "    \n",
    "    misclass_counts = {true_label: len(misclass_tuple) for true_label, misclass_tuple in common_misclass_data.items()}\n",
    "    pt = PrettyTable(field_names=[f\"\\033[1m{field}\\033[0m\" for field in [\"True Label\", \"Misclassification Times\"]])\n",
    "    pt.add_rows([(true_label, count) for true_label, count in misclass_counts.items()])\n",
    "    print(pt)\n",
    "\n",
    "    misclass_freqs = defaultdict(int)\n",
    "    for true_label, values in common_misclass_data.items():\n",
    "        for text, pred_labels in values:\n",
    "            for pl in pred_labels:\n",
    "                misclass_freqs[(true_label, pl)] += 1\n",
    "    max_tuple, max_count = max(misclass_freqs.items(), key=lambda x: x[1])\n",
    "    print(\"\\033[1m\" + \"Most common Misclassification Pair:\" + \"\\033[0m\")\n",
    "    pt = PrettyTable(field_names=[f\"\\033[1m{field}\\033[0m\" for field in [\"True Label\", \"Predicted Label\", \"Frequency\"]])\n",
    "    pt.add_row([max_tuple[0], max_tuple[1], max_count])\n",
    "    print(pt)\n",
    "\n",
    "    rand_true_label = random.choice(list(common_misclass_data.keys()))\n",
    "    rand_misclass_tuple = random.choice(common_misclass_data[rand_true_label])\n",
    "    print(\"\\033[1m\" + \"Text: \" + \"\\033[0m\" + rand_misclass_tuple[0] + \"\\033[1m\" + \"\\nTrue Label: \" + \"\\033[0m\" + rand_true_label)\n",
    "    pt = PrettyTable(field_names=[f\"\\033[1m{field}\\033[0m\" for field in [\"Model\", \"Prediction\"]])\n",
    "    pt.add_rows([(model, rand_misclass_tuple[1][idx]) for idx, model in enumerate([\"mnv1w\", \"mnv3c\", \"svm1w\", \"svm3c\"])])\n",
    "    print(pt)\n",
    "\n",
    "analyze_results(misclass_data_mnv1w, misclass_data_mnv3c, misclass_data_svm1w, misclass_data_svm3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8e160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
