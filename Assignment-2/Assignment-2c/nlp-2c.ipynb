{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nataliakoliou/NLP-Various-Implementations/blob/main/Assignment-2/Assignment-2c/nlp-2c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`❕`** <font size=\"2\">**WARNING:** Some of the code lines in this notebook may be cropped out due to display limitations. To view the entire code properly, please click on this [link](https://nbviewer.org/github/nataliakoliou/NLP-Various-Implementations/blob/main/Assignment-2/Assignment-2c/nlp-2c.ipynb) to open the notebook in nbviewer or this [link](https://colab.research.google.com/github/nataliakoliou/NLP-Various-Implementations/blob/main/Assignment-2/Assignment-2c/nlp-2c.ipynb) to open the notebook in Google Colab.</font>"
      ],
      "metadata": {
        "id": "-UqtMeGD7dfd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-6PFkBypCfn"
      },
      "source": [
        "# **NLP-Various Implementations | Text Classification with RNNs**\n",
        "\n",
        "**Overview:** In this part of the project, I trained several neural network models, including RNNs and LSTMs, with different architectures and hyperparameters to evaluate their performance on some simple classification tasks. For this purpose, I used the AG News Topic Classification and the IMDB movie review12 datasets. Overall, this work provided me with valuable hands-on experience in training neural networks and insight into the factors that affect their performance in text classification tasks. Through experimenting with different architectures and hyperparameters, I gained a deeper understanding of how these models operate and can be optimized to achieve high accuracy levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-p_LzB2r7QV"
      },
      "source": [
        "## **1. Import all the necessary modules**\n",
        "\n",
        "**Briefly:** `time` library provides functions for working with time-related tasks, `torch` library provides support for deep learning operations using tensors, `random` library provides tools for generating random numbers and `pandas` library provides data manipulation and analysis tools. Additionaly, `nn` module provides support for building neural networks, `tqdm` library provides a progress bar to track loops, `defaultdict` class provides a way to create a dictionary with default values for nonexistent keys, `PrettyTable` library provides a way to display data in a table format, `functional` module provides support for functional-style programming with neural networks, `FiDataLoader` class provides a way to load data in batches for training neural networks, `get_tokenizer` function provides a way to tokenize text and `build_vocab_from_iterator` function provides a way to build a vocabulary from an iterator of text. Finally, `accuracy_score` provides a way to calculate the accuracy of a model, along with other useful metrics such as `classification_report` and `confusion_matrix`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_-67_ZIz2VLQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from prettytable import PrettyTable\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_h3jKbStQvI"
      },
      "source": [
        "## **2. Define and initialize the models' parameters**\n",
        "\n",
        "The set_device function checks if a CUDA-enabled GPU is available and sets the device accordingly. The tokenizer variable is set to tokenize the text data using the \"basic_english\" tokenizer. Both models and classes are lists that contain the different models and classes used for the classification process, whereas accuracies, parameters, and time_costs are empty lists that will be used to store evaluation metrics during the training process. Finally, the remaining variables are hyperparameters used for this training process.\n",
        "\n",
        "* The `models` listed in the models list are different types of neural network models that will be used for classification. Specifically, they are variations of recurrent neural networks (RNNs) and long short-term memory (LSTM) networks with different numbers of layers and types of connections between layers.\n",
        "\n",
        "* The `classes` list specifies the different categories or classes that the classification model will be trained to predict. In this case, we have four classes: World, Sports, Business, and Sci/Tech. This suggest that our model will be trained to classify news articles or text documents into these four broad categories.\n",
        "\n",
        "* `MAX_WORDS = 25` sets a maximum limit for the number of words allowed in a text sample. This means that if a text sample contains more than 25 words, it will be truncated to 25 words before being fed into the classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BkO4z42A2W-C"
      },
      "outputs": [],
      "source": [
        "def set_device(primary, secondary):\n",
        "    return torch.device(primary if torch.cuda.is_available() else secondary) # device used to perform the computations for the machine learning model\n",
        "\n",
        "device = set_device(\"cuda\",\"cpu\")\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "models = [\"1Uni-RNN\", \"1Bi-RNN\", \"2Bi-RNN\", \"1Uni-LSTM\", \"1Bi-LSTM\", \"2Bi-LSTM\"]; classes = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]; accuracies = []; parameters = []; time_costs = []\n",
        "MIN_FREQ = 10 ; MAX_WORDS = 25; EPOCHS = 15; LEARNING_RATE = 1e-3; BATCH_SIZE = 1024; EMBEDDING_DIM = 100; HIDDEN_DIM = 64; PADDED = \"<PAD>\"; UNKNOWN = \"<UNK>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z62FB_A1xjFs"
      },
      "source": [
        "## **3. Load and preprocess the training and testing datasets**\n",
        "\n",
        "The load_dataset() function is used to load and preprocess a CSV file containing text data. It reads the CSV file using pandas, shuffles the rows (except the first one), and selects a subset of the data based on the given percent and mode arguments. It then combines the selected features into a single text column and returns a list of tuples, where each tuple contains the label and text data for each row of the dataset. The function is called twice to create train_dataset and test_dataset, which are used for training and testing a machine learning model.\n",
        "\n",
        "* `data.iloc[:1]` selects only the first row of the data, which typically contains column names that correspond to our models' classes. By selecting only the data rows for shuffling, we ensure that the column names remain in the first row (for later use) and are not affected by the shuffling process.\n",
        "\n",
        "* If `mode` is set to *start*, the first percent % of rows are selected, whereas if `mode` is set to *end*, the last percent % of rows are selected. The code calculates the starting and ending indexes based on the percent value and the total length of the dataset using integer division and multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sEE-_zcH27Ji"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path, features, label, percent, mode):\n",
        "    data = pd.read_csv(path)\n",
        "    data = pd.concat([data.iloc[:1], data.iloc[1:].sample(frac=1)], ignore_index=True)  # shuffle all rows except the first one\n",
        "    if mode == 'start':\n",
        "        end_index = int(len(data) * (percent / 100))\n",
        "        data = data.iloc[:end_index]\n",
        "    elif mode == 'end':\n",
        "        start_index = int(len(data) * ((100 - percent) / 100))\n",
        "        data = pd.concat([data.iloc[0:0], data.iloc[start_index:]], ignore_index=True)\n",
        "    text = data[features].astype(str).agg(' '.join, axis=1)\n",
        "    return [(data[label][i], text[i]) for i in range(len(data))]\n",
        "\n",
        "train_dataset, test_dataset = load_dataset(\"train.csv\", [\"Title\",\"Description\"], \"Class Index\", 100, \"start\"), load_dataset(\"test.csv\", [\"Title\",\"Description\"], \"Class Index\", 100, \"start\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8UGzQCv0sTV"
      },
      "source": [
        "## **4. Build PyTorch DataLoaders for efficient model training and testing**\n",
        "\n",
        "The generate_loader() function takes in a dataset, a maximum number of words, a batch size, and a shuffle flag, and returns a PyTorch DataLoader object with the specified parameters. The collate_batch() function is used as a custom collate function for the DataLoader, and it preprocesses the input data by tokenizing the text, padding the sequences with <PAD> tokens or truncating the sequences to a maximum length of max_words, and converting the data into PyTorch tensors. The DataLoader is then split into train_loader and test_loader, with train_loader being shuffled for better model training and test_loader being unshuffled for model evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lGyv6CVS3TLs"
      },
      "outputs": [],
      "source": [
        "def generate_loader(dataset, max_words, batch_size, shuffle):\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=lambda b: collate_batch(b, max_words))\n",
        "\n",
        "def collate_batch(batch, max_words):\n",
        "    Y, X = list(zip(*batch))\n",
        "    Y = torch.tensor(Y) - 1  # target names in range [0,1,2,3] instead of [1,2,3,4]\n",
        "    X = [vocab(tokenizer(text)) for text in X] # type(X): list of lists\n",
        "    X = [tokens+([vocab['<PAD>']]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X]  # brings all samples to MAX_WORDS length - shorter texts are padded with <PAD> sequences, longer texts are truncated\n",
        "    return torch.tensor(X, dtype=torch.int32).to(device), Y.to(device)\n",
        "\n",
        "train_loader, test_loader = generate_loader(train_dataset, MAX_WORDS, BATCH_SIZE, True), generate_loader(test_dataset, MAX_WORDS, BATCH_SIZE, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwt7AbnY7WS8"
      },
      "source": [
        "## **5. Build the vocabulary from the training and testing datasets**\n",
        "\n",
        "The build_vocab() function takes in datasets, min_freq, padded, and unknown as input parameters. It uses the tokenize() function to iterate over all the text in the datasets and tokenize them. Then, it builds a vocabulary from the tokens using build_vocab_from_iterator() with min_freq, padded, and unknown as arguments. It sets the default index to the index of the unknown token. Finally, it returns the vocabulary. The code then calls build_vocab() with train_dataset and test_dataset as datasets, MIN_FREQ, PADDED, and UNKNOWN as input arguments and assigns the returned vocabulary to vocab.\n",
        "\n",
        "* `set_default_index(vocab[unknown])` means that if a word is not present in the vocabulary, its index will be the same as the index of the unknown token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5O_ZmNhb318J"
      },
      "outputs": [],
      "source": [
        "def build_vocab(datasets, min_freq, padded, unknown):\n",
        "    vocab = build_vocab_from_iterator(tokenize(datasets), min_freq=min_freq, specials=[padded, unknown])\n",
        "    vocab.set_default_index(vocab[unknown])\n",
        "    return vocab\n",
        "\n",
        "def tokenize(datasets):\n",
        "    for dataset in datasets:\n",
        "        for _, text in dataset:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab([train_dataset, test_dataset], MIN_FREQ, PADDED, UNKNOWN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrLVOOEj7YVE"
      },
      "source": [
        "## **6. RNN & LSTM models trained on AGNTC dataset with sequence length of 25 words**\n",
        "\n",
        "The setup_model function sets up a classification model, which takes in the model type, the number of output classes, the vocab and other parameters such as embedding_dim, hidden_dim, num_layers, bidirectional, learning_rate, embeddings, and freeze. It returns the classifier the cross-entropy loss and Adam optimizer).\n",
        "\n",
        "The RNN_model class is defined as a subclass of nn.Module and has a constructor that sets up the model architecture. The RNN_model constructor uses the get_directions function to determine the size of the hidden state based on whether or not the RNN is bidirectional. The get_directions function returns 2 if the RNN is bidirectional and 1 otherwise, which is used to compute the size of the hidden state in the linear layer. This ensures that the output of the RNN can be fed into the linear layer correctly, regardless of whether or not the RNN is bidirectional.\n",
        "\n",
        "* `hidden_size` is set to the product of hidden_dim and the number of directions, which is either 1 or 2 depending on the bidirectional parameter. This is because in a bidirectional RNN, the number of hidden units in the forward and backward directions are added together to obtain the total number of hidden units, whereas in a unidirectional RNN, there is only one set of hidden units.\n",
        "\n",
        "* `nn.Linear` is then defined with an input size equal to hidden_dim times the number of directions, and an output size of output_dim. This linear layer is used to map the final hidden state of the RNN to the output classes.\n",
        "\n",
        "The forward function takes in a batch of input data X_batch and passes it through the model. The input data is first passed through an embedding layer to transform it into a dense vector representation. This embedding is then fed into an RNN layer, which processes the input data sequence and produces output at each time step. The output of the RNN is concatenated and passed through a linear layer to produce the final output logits, which are then passed through a softmax function to generate class probabilities. The final probabilities are returned as the output of the forward pass.\n",
        "\n",
        "* `output_concat` is created by concatenating the last hidden_size units of the forward and backward RNN outputs. The output tensor has shape (batch_size, sequence_length, hidden_size*num_directions), so output[:, :, :self.hidden_size] selects the forward outputs and output[:, :, self.hidden_size:] selects the backward outputs.\n",
        "\n",
        "* the : in `output_concat[:, :, :]` means that we include all elements in the first two dimensions of the tensor (i.e., the batch size and the number of hidden units in the linear layer). The -1 in output_concat[:, -1, :] means that we only take the last element along the second dimension (i.e., the last hidden state of the concatenated RNN outputs). \n",
        "\n",
        "### **6.1. Unidirectional RNN model with 1 layer**\n",
        "\n",
        "**6.1.1. Set-up model:** An instance of the RNN_model is created and passed as an argument to setup_model function along with other hyperparameters, to set up a specific configuration of the model - in this case: unidirectional RNN model with 1 layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hcWFZq-Q4DkB"
      },
      "outputs": [],
      "source": [
        "def setup_model(device, model, classes, vocab, embedding_dim, hidden_dim, num_layers, bidirectional, learning_rate, embeddings, freeze):\n",
        "    classifier = model(len(vocab), embedding_dim, hidden_dim, num_layers, bidirectional, len(classes), embeddings, freeze).to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam([param for param in classifier.parameters() if param.requires_grad == True],lr=learning_rate)\n",
        "    return classifier, loss_fn, optimizer\n",
        "  \n",
        "class RNN_model(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, bidirectional, output_dim, none, freeze):\n",
        "        super(RNN_model, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=input_dim, embedding_dim=embedding_dim)\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
        "        self.hidden_size = hidden_dim * get_directions(bidirectional)\n",
        "        self.linear = nn.Linear(hidden_dim * get_directions(bidirectional), output_dim)\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings)\n",
        "        output_concat = torch.cat([output[:, :, :self.hidden_size], output[:, :, self.hidden_size:]], dim=2) # concatenates outputs\n",
        "        logits = self.linear(output_concat[:, -1, :]) # the last output of the concatenated RNN is used for sequence classification\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return probs\n",
        "\n",
        "def get_directions(bidirectional):\n",
        "    return 2 if bidirectional else 1\n",
        "\n",
        "classifier, loss_fn, optimizer = setup_model(device, RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, False, LEARNING_RATE, None, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01e0OOZy7cI0"
      },
      "source": [
        "The train_model function trains the classifier model using the specified loss function and an optimizer over a specified number of epochs. The function iterates through batches of data in the training loader and updates the model weights using backpropagation after computing the loss. It calculates the training loss at the end of each epoch and prints it. Finally, it returns the average time taken for each epoch. The train_model function is called with the specified parameters and the returned time_cost variable stores the average time taken for each epoch.\n",
        "\n",
        "**6.1.2. Train the model:** The train_model function is called with the specified parameters. The time_cost variable stores the average time taken for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tyx3S5lVKI9",
        "outputId": "601541cc-392b-48cd-bd15-9708763952b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.293\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.059\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 23.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.970\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.931\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.908\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 23.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.890\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.878\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.869\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.862\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.858\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.850\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.846\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.842\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 23.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.839\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.837\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def train_model(classifier, loss_fn, optimizer, train_loader, epochs):\n",
        "    times = []\n",
        "    for i in range(1, epochs+1):\n",
        "        classifier.train()\n",
        "        print('\\033[1mEpoch\\033[0m:',i)\n",
        "        losses = []\n",
        "        start_time = time.time()\n",
        "        for X, Y in tqdm(train_loader):\n",
        "            Y_preds = classifier(X)\n",
        "            loss = loss_fn(Y_preds, Y)\n",
        "            losses.append(loss.item())\n",
        "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "        epoch_time = time.time() - start_time\n",
        "        times.append(epoch_time)\n",
        "        print(\"\\033[1mTrain Loss\\033[0m: {:.3f}\\n\".format(torch.tensor(losses).mean()))\n",
        "    return sum(times)/len(times)\n",
        "\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluate_model function sets the classifier to evaluation mode and then evaluates the performance of the model on the test data. It uses the classifier to make predictions on the test data and computes the loss for each prediction. The actual and predicted labels are then converted to numpy arrays using the detach() and cpu() functions. The function then detects misclassified data using another helper function called detect_misclassification. Finally, the function prints the accuracy of the model on the test data, the classification report and confusion matrix. It then returns the mean loss, the actual and predicted labels, and the misclassified data.\n",
        "\n",
        "The detect_misclassification() function takes in three arguments: test_data, which is a dictionary containing the features and labels of the test dataset, Y_actual, which is a list of the true labels of the test data, and Y_preds, which is a list of the predicted labels of the test data. The function then iterates over each data point in the test dataset and compares the true label with the predicted label. If they are not the same, it appends the corresponding text and predicted label to the misclass_data dictionary, which is returned at the end.\n",
        "\n",
        "The to_dict() function takes in a list of tuples, where each tuple contains a label and a feature, and returns a dictionary with two keys: features and labels. The features key holds a list of all the features in the tuples, and the labels key holds a list of all the labels in the tuples.\n",
        "\n",
        "**6.1.3. Evaluate the model:** The evaluate_model function is called with the necessary parameters. The returned values are stored in variables for later use."
      ],
      "metadata": {
        "id": "B7XTXF0fNp1c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RQgh1Om0Vo7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041e57c2-ef93-44cb-c942-f06b331c51f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTest Accuracy\u001b[0m: 0.862\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.89      0.86      0.87      1900\n",
            "      Sports       0.92      0.92      0.92      1900\n",
            "    Business       0.83      0.81      0.82      1900\n",
            "    Sci/Tech       0.81      0.85      0.83      1900\n",
            "\n",
            "    accuracy                           0.86      7600\n",
            "   macro avg       0.86      0.86      0.86      7600\n",
            "weighted avg       0.86      0.86      0.86      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1637   85   91   87]\n",
            " [  46 1753   74   27]\n",
            " [  66   35 1543  256]\n",
            " [  94   28  158 1620]]\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(classes, classifier, loss_fn, test_loader, test_data):\n",
        "    classifier.eval()\n",
        "    with torch.no_grad():  # during evaluation we don't update the model's parameters\n",
        "        Y_actual, Y_preds, losses = [],[],[]\n",
        "        for X, Y in test_loader:\n",
        "            preds = classifier(X)\n",
        "            loss = loss_fn(preds, Y)\n",
        "            losses.append(loss.item())\n",
        "            Y_actual.append(Y)\n",
        "            Y_preds.append(preds.argmax(dim=-1))\n",
        "        Y_actual, Y_preds = torch.cat(Y_actual), torch.cat(Y_preds)\n",
        "        Y_actual, Y_preds = Y_actual.detach().cpu().numpy(), Y_preds.detach().cpu().numpy()\n",
        "        misclass_data = detect_misclassification(test_data, Y_actual, Y_preds)\n",
        "        print(\"\\033[1mTest Accuracy\\033[0m: {:.3f}\\n\".format(accuracy_score(Y_actual, Y_preds)))\n",
        "        print(\"\\033[1mClassification Report:\\033[0m\\n\", classification_report(Y_actual, Y_preds, target_names=classes))\n",
        "        print(\"\\033[1mConfusion Matrix:\\033[0m\\n\", confusion_matrix(Y_actual, Y_preds))\n",
        "    return torch.tensor(losses).mean(), Y_actual, Y_preds, misclass_data      \n",
        "\n",
        "def detect_misclassification(test_data, Y_actual, Y_preds):\n",
        "    misclass_data = defaultdict(list)\n",
        "    for i in range(len(Y_actual)):\n",
        "        true_label = Y_actual[i]\n",
        "        predicted_label = Y_preds[i]\n",
        "        if true_label != predicted_label:\n",
        "            text = test_data[\"features\"][i]\n",
        "            misclass_data[true_label].append((text, predicted_label))\n",
        "    return misclass_data\n",
        "\n",
        "def to_dict(tuples_list):\n",
        "    return {'features': [d[1] for d in tuples_list], 'labels': [d[0] for d in tuples_list]}\n",
        "\n",
        "_, Y_actual, Y_preds, misclass_data_1UniRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function count_parameters calculates the number of trainable parameters in a PyTorch model. The accuracies, parameters, and time_costs lists are then updated with the accuracy score, parameter count, and time cost of the model. As we'll see, these values will be stored for each model separately and will later be used to create a pretty table for comparison."
      ],
      "metadata": {
        "id": "EufvULhRNzRT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "l8anMr3JWJzz"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.2. Bidirectional RNN model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional RNN with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "6WuO1s58Nzxa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O71o-crdWK8L",
        "outputId": "ac9ee1da-bbc8-4f11-cb36-b2416f4d7ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.305\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.076\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.979\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.934\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.911\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.893\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.881\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.873\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.865\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.859\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.854\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.849\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.845\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.842\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.839\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.864\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.86      0.88      0.87      1900\n",
            "      Sports       0.91      0.94      0.92      1900\n",
            "    Business       0.86      0.80      0.83      1900\n",
            "    Sci/Tech       0.83      0.85      0.84      1900\n",
            "\n",
            "    accuracy                           0.86      7600\n",
            "   macro avg       0.86      0.86      0.86      7600\n",
            "weighted avg       0.86      0.86      0.86      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1669   88   82   61]\n",
            " [  61 1778    8   53]\n",
            " [ 136   26 1514  224]\n",
            " [  73   55  165 1607]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1BiRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.3. Bidirectional RNN model with 2 layers**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional RNN with two layers. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "RI9ZM3_-N0mZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvvcYm6XWYJZ",
        "outputId": "c276d84f-0852-4a58-d989-f6bbfa17e335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.255\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.052\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 23.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.986\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.962\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.938\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.922\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.916\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.919\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.899\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.889\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.889\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.883\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.880\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.875\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.878\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.845\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.86      0.87      0.86      1900\n",
            "      Sports       0.92      0.94      0.93      1900\n",
            "    Business       0.81      0.75      0.78      1900\n",
            "    Sci/Tech       0.79      0.82      0.80      1900\n",
            "\n",
            "    accuracy                           0.85      7600\n",
            "   macro avg       0.84      0.85      0.84      7600\n",
            "weighted avg       0.84      0.85      0.84      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1649   72  103   76]\n",
            " [  74 1788   16   22]\n",
            " [ 120   32 1428  320]\n",
            " [  72   57  212 1559]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 2, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_2BiRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LSTM_model class is defined as a subclass of nn.Module and has a constructor that sets up the model architecture. The LSTM_model constructor uses the get_directions function to determine the size of the hidden state based on whether or not the LSTM is bidirectional. The get_directions function returns 2 if the LSTM is bidirectional and 1 otherwise, which is used to compute the size of the hidden state in the linear layer. This ensures that the output of the LSTM can be fed into the linear layer correctly, regardless of whether or not the LSTM is bidirectional.\n",
        "\n",
        "* `hidden_size` is set to the product of hidden_dim and the number of directions, which is either 1 or 2 depending on the bidirectional parameter. This is because in a bidirectional LSTM, the number of hidden units in the forward and backward directions are added together to obtain the total number of hidden units, whereas in a unidirectional LSTM, there is only one set of hidden units.\n",
        "\n",
        "* `nn.Linear` is then defined with an input size equal to hidden_dim times the number of directions, and an output size of output_dim. This linear layer is used to map the final hidden state of the LSTM to the output classes.\n",
        "\n",
        "The forward function takes in a batch of input data X_batch and passes it through the model. The input data is first passed through an embedding layer to transform it into a dense vector representation. This embedding is then fed into an LSTM layer, which processes the input data sequence, produces the output at each time step and updates the hidden and cell state. The output of the LSTM is concatenated and passed through a linear layer to produce the final output logits, which are then passed through a softmax function to generate class probabilities. The final probabilities are returned as the output of the forward pass.\n",
        "\n",
        "* `output_concat` is created by concatenating the last hidden_size units of the forward and backward LSTM outputs. The output tensor has shape (batch_size, sequence_length, hidden_size*num_directions), so output[:, :, :self.hidden_size] selects the forward outputs and output[:, :, self.hidden_size:] selects the backward outputs.\n",
        "\n",
        "* the : in `output_concat[:, :, :]` means that we include all elements in the first two dimensions of the tensor (i.e., the batch size and the number of hidden units in the linear layer). The -1 in output_concat[:, -1, :] means that we only take the last element along the second dimension (i.e., the last hidden state of the concatenated LSTM outputs).\n",
        "\n",
        "### **6.4. Unidirectional LSTM model with 1 layer**\n",
        "\n",
        "An instance of the LSTM_model is created and passed as an argument to setup_model function along with other hyperparameters, to set up a specific configuration of the model - in this case: unidirectional LSTM model with 1 layer. The train_model function is called with the specified parameters. The time_cost variable stores the average time taken for each epoch. The evaluate_model function is called with the necessary parameters. The returned values are stored in variables for later use. The accuracies, parameters, and time_costs lists are then updated with the accuracy score, parameter count, and time cost of the model. As we'll see, these values will be stored for each model separately and will later be used to create a pretty table for comparison."
      ],
      "metadata": {
        "id": "L1wM3Zk5qC0q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSt0QpUnWcAk",
        "outputId": "5e495900-720a-47b3-d955-7f63af5c26b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.252\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.979\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.912\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.882\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.863\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.851\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.842\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.835\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.828\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.824\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.820\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.817\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.814\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.812\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 19.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.810\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.884\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.90      0.88      0.89      1900\n",
            "      Sports       0.94      0.95      0.94      1900\n",
            "    Business       0.86      0.83      0.85      1900\n",
            "    Sci/Tech       0.84      0.89      0.86      1900\n",
            "\n",
            "    accuracy                           0.88      7600\n",
            "   macro avg       0.88      0.88      0.88      7600\n",
            "weighted avg       0.88      0.88      0.88      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1663   59   98   80]\n",
            " [  44 1796   27   33]\n",
            " [  75   32 1578  215]\n",
            " [  67   25  124 1684]]\n"
          ]
        }
      ],
      "source": [
        "class LSTM_model(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, bidirectional, output_dim, none, freeze):\n",
        "        super(LSTM_model, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=input_dim, embedding_dim=embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
        "        self.hidden_size = hidden_dim * get_directions(bidirectional)\n",
        "        self.linear = nn.Linear(hidden_dim * get_directions(bidirectional), output_dim)\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, (hidden, cell) = self.lstm(embeddings)\n",
        "        output_concat = torch.cat([output[:, :, :self.hidden_size], output[:, :, self.hidden_size:]], dim=2) # concatenates outputs\n",
        "        logits = self.linear(output_concat[:, -1, :]) # the last output of the concatenated LSTM is used for sequence classification\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return probs\n",
        "\n",
        "classifier, loss_fn, optimizer = setup_model(device, LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, False, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1UniLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.5. Bidirectional LSTM model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional LSTM with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "_ArSoY6rzSnB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOCwPy5pWfFj",
        "outputId": "e9a573b0-01a2-4edf-ca3c-df15e01d9d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.258\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.980\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.914\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.885\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.867\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.855\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.844\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.836\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.831\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.826\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.821\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.817\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.814\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.812\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.810\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.882\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.90      0.88      0.89      1900\n",
            "      Sports       0.93      0.94      0.94      1900\n",
            "    Business       0.85      0.83      0.84      1900\n",
            "    Sci/Tech       0.84      0.87      0.86      1900\n",
            "\n",
            "    accuracy                           0.88      7600\n",
            "   macro avg       0.88      0.88      0.88      7600\n",
            "weighted avg       0.88      0.88      0.88      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1676   63   88   73]\n",
            " [  43 1788   43   26]\n",
            " [  73   36 1579  212]\n",
            " [  74   30  137 1659]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1BiLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.6. Bidirectional LSTM model with 2 layers**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional LSTM with two layers. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "hqdxcG3_zc15"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UHALeleXFLL",
        "outputId": "d2c88460-4931-4f59-9f0b-0c8f843d1183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.191\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 16.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.951\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.899\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.873\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.857\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 16.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.846\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.838\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.832\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.827\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.826\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.820\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.818\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 16.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.814\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.811\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.811\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.881\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.91      0.87      0.89      1900\n",
            "      Sports       0.94      0.93      0.94      1900\n",
            "    Business       0.84      0.86      0.85      1900\n",
            "    Sci/Tech       0.84      0.86      0.85      1900\n",
            "\n",
            "    accuracy                           0.88      7600\n",
            "   macro avg       0.88      0.88      0.88      7600\n",
            "weighted avg       0.88      0.88      0.88      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1652   59  110   79]\n",
            " [  31 1775   35   59]\n",
            " [  65   27 1627  181]\n",
            " [  64   26  171 1639]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 2, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_2BiLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Visualize the performance metrics of the models**\n",
        "\n",
        "The visualize function takes four arguments: models, accuracies, parameters, and time_costs. It creates a PrettyTable object with four columns, sets the column names to Model, Accuracy, Parameters, and Time Cost, and then adds rows to the table based on the values in the input lists. Specifically, for each model in the models list, the function retrieves the corresponding accuracy, parameters, and time cost and adds them to a new row in the table. The code then calls this visualize function to create and print this table."
      ],
      "metadata": {
        "id": "nKaCoxGTzq_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUBnnjL2XF67",
        "outputId": "a1f9c584-41fc-4540-fc5b-7ad67d0942d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+------------+-----------+\n",
            "|   \u001b[1mModel\u001b[0m   | \u001b[1mAccuracy\u001b[0m | \u001b[1mParameters\u001b[0m | \u001b[1mTime Cost\u001b[0m |\n",
            "+-----------+----------+------------+-----------+\n",
            "|  1Uni-RNN |  0.8622  |  2136284   |   4.6727  |\n",
            "|  1Bi-RNN  |  0.8642  |  2147164   |   4.9244  |\n",
            "|  2Bi-RNN  |  0.8453  |  2171996   |   5.2599  |\n",
            "| 1Uni-LSTM |  0.8843  |  2168156   |   5.1549  |\n",
            "|  1Bi-LSTM |  0.8818  |  2210908   |   5.852   |\n",
            "|  2Bi-LSTM |  0.8807  |  2310236   |   6.6313  |\n",
            "+-----------+----------+------------+-----------+\n"
          ]
        }
      ],
      "source": [
        "def visualize(models, accuracies, parameters, time_costs):\n",
        "    pt = PrettyTable(field_names=[f\"\\033[1m{field}\\033[0m\" for field in [\"Model\", \"Accuracy\", \"Parameters\", \"Time Cost\"]])\n",
        "    [pt.add_row([model, round(accuracies[i], 4), parameters[i], round(time_costs[i], 4)]) for i, model in enumerate(models)]\n",
        "    print(pt)\n",
        "\n",
        "visualize(models, accuracies, parameters, time_costs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`####################################################`"
      ],
      "metadata": {
        "id": "_jmD8r908yAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. Analyze the results of the models**\n",
        "\n",
        "The analyze_results function analyzes the results of a classification task by taking in the classes, models used and the misclassified texts. It creates a dictionary common_misclass_data to store the texts that were misclassified by all the models. For each text that was misclassified, it looks at the true label and stores the text along with the predicted labels from all the models in a list. It then calls other helper functions, count_times(), get_top_pair() and get_random_text(), to further analyze the data in terms of misclassification.\n",
        "\n",
        "* `labels` is a list that stores all the predicted labels for every single text that is misclassified by the first model. The first element in labels is the predicted label of the first model, and the remaining elements are ether the predicted labels of the other models if they misclassified that text, or an empty string otherwise.\n",
        "\n",
        "* `(text, labels)` is added to the list corresponding to the key true_label in the dictionary common_misclass_data only if all elements in labels are non-empty strings. If not, the else statement returns None. The reason we do this is to identify common text misclassifications across all models.\n",
        "\n",
        "\n",
        "The count_times function takes as input the common_misclass_data dictionary and the list of classes that contains all the possible labels in the dataset. It first counts the number of misclassified texts for each true label by computing the length of the corresponding dictionary value (which is a list of tuples where each tuple contains a misclassified text and its predicted labels from all models). Then, it creates a pretty table to display the number of common misclassified texts for each true label across all models.\n",
        "\n",
        "The get_top_pair function takes as input the common_misclass_data dictionary and the list of classes that contains all the possible labels in the dataset. It then iterates through each true label and the corresponding misclassified texts, and counts the number of times each pair of true label and predicted label occurs in the list of misclassified texts. It then determines the pair with the highest count and prints it as the most common misclassification pair. Finally, the function creates a PrettyTable object to display the frequencies of all the misclassification pairs, sorted in descending order by frequency.\n",
        "\n",
        "The get_random_text function takes as input the list of all the RNN and LSTM models we used, the common_misclass_data dictionary and the list of classes that contains all the possible labels in the dataset. It randomly selects a misclassified text and displays it along with its true label. It then shows the predictions made by each model in a table. The purpose of this function is to allow the user to see an example of a misclassified text and the various predictions made by the models for that text.\n",
        "\n",
        "The to_category function takes a numerical label as input, along with a list of classes, and returns the corresponding string label for that numerical value."
      ],
      "metadata": {
        "id": "ltwwjWQgBb_N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fOMMmND4qD9",
        "outputId": "89a8cbde-27e1-4f9c-b006-b285775e4d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mCommon Misclassified Texts per Class:\u001b[0m\n",
            "+------------+---------------------+\n",
            "| \u001b[1mTrue Label\u001b[0m | \u001b[1mMisclassified Texts\u001b[0m |\n",
            "+------------+---------------------+\n",
            "|  Sci/Tech  |          45         |\n",
            "|  Business  |          83         |\n",
            "|   World    |         110         |\n",
            "|   Sports   |          6          |\n",
            "+------------+---------------------+\n",
            "\n",
            "\u001b[1mMost common Misclassification Pair:\u001b[0m (Business, Sci/Tech)\n",
            "+------------+-----------------+-----------+\n",
            "| \u001b[1mTrue Label\u001b[0m | \u001b[1mPredicted Label\u001b[0m | \u001b[1mFrequency\u001b[0m |\n",
            "+------------+-----------------+-----------+\n",
            "|  Business  |     Sci/Tech    |    461    |\n",
            "|   World    |     Business    |    280    |\n",
            "|  Sci/Tech  |     Business    |    247    |\n",
            "|   World    |      Sports     |    216    |\n",
            "|   World    |     Sci/Tech    |    164    |\n",
            "|  Business  |      Sports     |     37    |\n",
            "|   Sports   |     Business    |     25    |\n",
            "|  Sci/Tech  |      Sports     |     23    |\n",
            "|   Sports   |     Sci/Tech    |     11    |\n",
            "+------------+-----------------+-----------+\n",
            "\n",
            "\u001b[1mRandom Text: \u001b[0mAncient fungus 'revived' in lab Fungus from a deep-sea sediment core that is hundreds of thousands of years old will grow when placed in culture, scientists discover.\u001b[1m\n",
            "True Label: \u001b[0mWorld\n",
            "+-----------+------------+\n",
            "|   \u001b[1mModel\u001b[0m   | \u001b[1mPrediction\u001b[0m |\n",
            "+-----------+------------+\n",
            "|  1Uni-RNN |  Sci/Tech  |\n",
            "|  1Bi-RNN  |  Sci/Tech  |\n",
            "|  2Bi-RNN  |  Sci/Tech  |\n",
            "| 1Uni-LSTM |  Sci/Tech  |\n",
            "|  1Bi-LSTM |  Sci/Tech  |\n",
            "|  2Bi-LSTM |  Sci/Tech  |\n",
            "+-----------+------------+\n"
          ]
        }
      ],
      "source": [
        "def analyze_results(classes, models, misclassified):\n",
        "    common_misclass_data = defaultdict(list)\n",
        "    for true_label in misclassified[0].keys():\n",
        "        for text, label in misclassified[0][true_label]:\n",
        "            labels = [label] + [next((l for t, l in model[true_label] if t == text), '') for model in misclassified[1:]]\n",
        "            common_misclass_data[true_label].append((text, labels)) if all(labels) else None\n",
        "    count_times(common_misclass_data, classes)\n",
        "    get_top_pair(common_misclass_data, classes)\n",
        "    get_random_text(models, common_misclass_data, classes)\n",
        "\n",
        "def count_times(common_misclass_data, classes):\n",
        "    misclass_counts = {true_label: len(misclass_tuples) for true_label, misclass_tuples in common_misclass_data.items()}\n",
        "    pt = PrettyTable(field_names=[f\"\\033[1m{field}\\033[0m\" for field in [\"True Label\", \"Misclassified Texts\"]])\n",
        "    [pt.add_row([to_category(true_label, classes), count]) for true_label, count in misclass_counts.items()]\n",
        "    print(\"\\033[1mCommon Misclassified Texts per Class:\\033[0m\")\n",
        "    print(pt)\n",
        "\n",
        "def get_top_pair(common_misclass_data, classes):\n",
        "    misclass_freqs = defaultdict(int)\n",
        "    for true_label, values in common_misclass_data.items():\n",
        "        for text, pred_labels in values:\n",
        "            for pl in pred_labels:\n",
        "                misclass_freqs[(true_label, pl)] += 1\n",
        "    max_tuple, max_count = max(misclass_freqs.items(), key=lambda x: x[1])\n",
        "    sorted_tuples = sorted(misclass_freqs.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(f\"\\n\\033[1mMost common Misclassification Pair:\\033[0m ({to_category(max_tuple[0], classes)}, {to_category(max_tuple[1], classes)})\")\n",
        "    pt = PrettyTable(field_names=[f\"\\033[1m{field}\\033[0m\" for field in [\"True Label\", \"Predicted Label\", \"Frequency\"]])\n",
        "    [pt.add_row([to_category(tup[0], classes), to_category(tup[1], classes), count]) for tup, count in sorted_tuples]\n",
        "    print(pt)\n",
        "\n",
        "def get_random_text(models, common_misclass_data, classes):\n",
        "    rand_true_label = random.choice(list(common_misclass_data.keys()))\n",
        "    rand_misclass_tuple = random.choice(common_misclass_data[rand_true_label])\n",
        "    print(\"\\n\\033[1m\" + \"Random Text: \" + \"\\033[0m\" + rand_misclass_tuple[0] + \"\\033[1m\" + \"\\nTrue Label: \" + \"\\033[0m\" + to_category(rand_true_label, classes))\n",
        "    pt = PrettyTable(field_names=[f\"\\033[1m{field}\\033[0m\" for field in [\"Model\", \"Prediction\"]])\n",
        "    [pt.add_row([model, to_category(rand_misclass_tuple[1][idx], classes)]) for idx, model in enumerate(models)]\n",
        "    print(pt)\n",
        "\n",
        "def to_category(label, classes):\n",
        "    return classes[label]\n",
        "\n",
        "analyze_results(classes, models, [misclass_data_1UniRNN, misclass_data_1BiRNN, misclass_data_2BiRNN, misclass_data_1UniLSTM, misclass_data_1BiLSTM, misclass_data_2BiLSTM])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`####################################################`"
      ],
      "metadata": {
        "id": "6Hj8VxF-9DZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9. RNN & LSTM models trained on AGNTC dataset with sequence length of 50 words**\n",
        "\n",
        "This is a variation of the previous implementation (see: Unit 6), where the MAX_WORDS hyperparameter is now set to 50 instead of 25. This means that only the first 50 words of each text in our dataset are used as input to the model. The train_loader and test_loader are generated using the generate_loader function, which takes in the train_dataset and test_dataset, along with the MAX_WORDS and BATCH_SIZE hyperparameters. The last argument specifies whether the data is used for training (value: True) or testing (value: False), respectively."
      ],
      "metadata": {
        "id": "GqhMmtKGQHr9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "98l70jeOcwL8"
      },
      "outputs": [],
      "source": [
        "MAX_WORDS = 50\n",
        "train_loader, test_loader = generate_loader(train_dataset, MAX_WORDS, BATCH_SIZE, True), generate_loader(test_dataset, MAX_WORDS, BATCH_SIZE, False)\n",
        "accuracies = []; parameters = []; time_costs = []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.1. Unidirectional RNN model with 1 layer**\n",
        "\n",
        "An instance of the RNN_model is created and passed as an argument to setup_model function along with other hyperparameters, to set up a specific configuration of the model - in this case: unidirectional RNN model with 1 layer. The train_model function is called with the specified parameters. The time_cost variable stores the average time taken for each epoch. The evaluate_model function is called with the necessary parameters. The returned values are stored in variables for later use. The accuracies, parameters, and time_costs lists are then updated with the accuracy score, parameter count, and time cost of the model. As we'll see, these values will be stored for each model separately and will later be used to create a pretty table for comparison."
      ],
      "metadata": {
        "id": "nQHVAfn6Rjj0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZVuqczklSkM",
        "outputId": "29a88715-f937-4888-92fc-d5bba28891d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.379\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.346\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.348\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.342\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.357\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.360\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.357\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.347\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.334\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.341\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:08<00:00, 13.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.333\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.286\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.329\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.343\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.338\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.342\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.40      0.18      0.25      1900\n",
            "      Sports       0.36      0.64      0.46      1900\n",
            "    Business       0.30      0.46      0.37      1900\n",
            "    Sci/Tech       0.37      0.08      0.13      1900\n",
            "\n",
            "    accuracy                           0.34      7600\n",
            "   macro avg       0.36      0.34      0.30      7600\n",
            "weighted avg       0.36      0.34      0.30      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[ 347  512  975   66]\n",
            " [  94 1218  489   99]\n",
            " [ 272  651  881   96]\n",
            " [ 154 1038  554  154]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, False, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1UniRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.2. Bidirectional RNN model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional RNN with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "0dpShFs0SBzv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy8-aqV2lkdc",
        "outputId": "46bde2cf-8c33-456d-817e-575277f350bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.374\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.354\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.330\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.305\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.282\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.312\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.344\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.272\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.283\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.218\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.179\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.160\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.118\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.100\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.129\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.614\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.56      0.86      0.67      1900\n",
            "      Sports       0.68      0.75      0.71      1900\n",
            "    Business       0.67      0.49      0.56      1900\n",
            "    Sci/Tech       0.58      0.36      0.45      1900\n",
            "\n",
            "    accuracy                           0.61      7600\n",
            "   macro avg       0.62      0.61      0.60      7600\n",
            "weighted avg       0.62      0.61      0.60      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1629  124  111   36]\n",
            " [ 139 1423   34  304]\n",
            " [ 709  102  928  161]\n",
            " [ 450  445  315  690]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1BiRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.3. Bidirectional RNN model with 2 layers**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional RNN with two layers. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "f-DrbY8RSNWt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ikzBdblmi3",
        "outputId": "937d0fc6-e08f-4cf0-e31c-1ffee0b6ccb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.378\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.333\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.343\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.293\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.271\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.266\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.283\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.280\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.281\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.251\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.269\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.283\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.257\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 19.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.248\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.275\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.456\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.51      0.54      0.52      1900\n",
            "      Sports       0.82      0.31      0.45      1900\n",
            "    Business       0.44      0.36      0.40      1900\n",
            "    Sci/Tech       0.35      0.61      0.45      1900\n",
            "\n",
            "    accuracy                           0.46      7600\n",
            "   macro avg       0.53      0.46      0.45      7600\n",
            "weighted avg       0.53      0.46      0.45      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1031   69  330  470]\n",
            " [ 267  581  164  888]\n",
            " [ 430   17  689  764]\n",
            " [ 304   42  392 1162]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 2, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_2BiRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.4. Unidirectional LSTM model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a unidirectional LSTM with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "ShqHWRKdSXDr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8pE3kK_lonM",
        "outputId": "7bdd4bd0-96af-4ebd-c766-c9cab7ac2deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.320\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.097\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.995\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.946\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.921\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.912\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.896\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.882\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.873\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.866\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.858\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.858\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.847\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.842\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.838\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.884\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.93      0.85      0.89      1900\n",
            "      Sports       0.93      0.96      0.95      1900\n",
            "    Business       0.86      0.83      0.85      1900\n",
            "    Sci/Tech       0.82      0.89      0.85      1900\n",
            "\n",
            "    accuracy                           0.88      7600\n",
            "   macro avg       0.89      0.88      0.88      7600\n",
            "weighted avg       0.89      0.88      0.88      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1615   81  123   81]\n",
            " [  14 1828    6   52]\n",
            " [  62   20 1582  236]\n",
            " [  45   35  126 1694]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, False, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1UniLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.5. Bidirectional LSTM model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional LSTM with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "aIXbOny4Sm3c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81Htqcx5lqQd",
        "outputId": "d92257c2-7e4d-4d55-a3a9-891cb439bd89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.338\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.078\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.963\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.920\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.898\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.887\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.872\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 16.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.861\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.856\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.856\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.848\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.844\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.844\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.844\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.840\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.878\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.92      0.85      0.89      1900\n",
            "      Sports       0.89      0.97      0.93      1900\n",
            "    Business       0.85      0.82      0.83      1900\n",
            "    Sci/Tech       0.85      0.87      0.86      1900\n",
            "\n",
            "    accuracy                           0.88      7600\n",
            "   macro avg       0.88      0.88      0.88      7600\n",
            "weighted avg       0.88      0.88      0.88      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1617  108  118   57]\n",
            " [  15 1848   15   22]\n",
            " [  69   59 1551  221]\n",
            " [  48   64  131 1657]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1BiLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.6. Bidirectional LSTM model with 2 layers**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional LSTM with two layers. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "iKA2ZH1_SwX2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR_0KAAslroM",
        "outputId": "d3741b50-48e4-4c3d-fc77-e68569366493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.353\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.265\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.048\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.953\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.907\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.886\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.870\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.859\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.852\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 16.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.844\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.840\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.837\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.832\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.827\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.825\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.882\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.90      0.87      0.89      1900\n",
            "      Sports       0.91      0.97      0.94      1900\n",
            "    Business       0.87      0.81      0.84      1900\n",
            "    Sci/Tech       0.85      0.87      0.86      1900\n",
            "\n",
            "    accuracy                           0.88      7600\n",
            "   macro avg       0.88      0.88      0.88      7600\n",
            "weighted avg       0.88      0.88      0.88      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1658   95   84   63]\n",
            " [  22 1836   11   31]\n",
            " [ 104   39 1547  210]\n",
            " [  53   47  139 1661]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 2, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_2BiLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10. Visualize the performance metrics of the models**\n",
        "\n",
        "The visualize function is called to generate and display tables that compare the performance of all the models trained above."
      ],
      "metadata": {
        "id": "IRYC-kBnTGY1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eGJ1IKlls3V",
        "outputId": "f49dbf1a-e253-4127-8ee9-d4276dcbf45a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+------------+-----------+\n",
            "|   \u001b[1mModel\u001b[0m   | \u001b[1mAccuracy\u001b[0m | \u001b[1mParameters\u001b[0m | \u001b[1mTime Cost\u001b[0m |\n",
            "+-----------+----------+------------+-----------+\n",
            "|  1Uni-RNN |  0.3421  |  2136284   |   5.561   |\n",
            "|  1Bi-RNN  |  0.6145  |  2147164   |   5.8997  |\n",
            "|  2Bi-RNN  |  0.4557  |  2171996   |   6.497   |\n",
            "| 1Uni-LSTM |  0.8841  |  2168156   |   6.0233  |\n",
            "|  1Bi-LSTM |  0.878   |  2210908   |   6.8385  |\n",
            "|  2Bi-LSTM |  0.8818  |  2310236   |   7.3513  |\n",
            "+-----------+----------+------------+-----------+\n"
          ]
        }
      ],
      "source": [
        "visualize(models, accuracies, parameters, time_costs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`################################################`"
      ],
      "metadata": {
        "id": "EqGoF8lUTn81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **11. RNN & LSTM models trained on AGNTC dataset with sequence length of 25 words and pre-trained word embeddings (glove-6B100d)**\n",
        "\n",
        "This is a variation of the very first implementation (see: Unit 6) that incorporates pre-trained word embeddings (glove-6B100d). The MAX_WORDS hyperparameter is set to 25, meaning that only the first 25 words of each text in the dataset are used as input to the model. The train_loader and test_loader are generated using the generate_loader function, which takes in the train_dataset and test_dataset, along with the MAX_WORDS and BATCH_SIZE hyperparameters. The last argument specifies whether the data is used for training (value: True) or testing (value: False), respectively."
      ],
      "metadata": {
        "id": "FsrrAkWPTq1s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GHExRVqwBCTH"
      },
      "outputs": [],
      "source": [
        "MAX_WORDS = 25\n",
        "train_loader, test_loader = generate_loader(train_dataset, MAX_WORDS, BATCH_SIZE, True), generate_loader(test_dataset, MAX_WORDS, BATCH_SIZE, False)\n",
        "models = [\"1Uni-preRNN\", \"1Bi-preRNN\", \"2Bi-preRNN\", \"1Uni-preLSTM\", \"1Bi-preLSTM\", \"2Bi-preLSTM\"]; accuracies = []; parameters = []; time_costs = []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The load_embeddings function loads pre-trained word embeddings from a file located at the specified path and extracts the embeddings only for the words present in the provided vocabulary vocab of the given dimension. It then returns a tensor of size len(vocab) × dimension, where each row represents the word embedding for a word in the vocabulary. In this case, the function is called with the arguments \"glove.6B.100d.txt\" as the file path to the pre-trained embeddings, vocab as the vocabulary containing the words for which we need the embeddings and EMBEDDING_DIM as the dimension of the word embeddings. Finally, the resulting embeddings are assigned to the embeddings variable."
      ],
      "metadata": {
        "id": "pKtjts2OX-Ss"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UWjOylygH6t-"
      },
      "outputs": [],
      "source": [
        "def load_embeddings(path, vocab, dimension):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    embeddings = torch.zeros(len(vocab), dimension)\n",
        "    for line in lines:\n",
        "        word, vec = line.strip().split(' ', 1)\n",
        "        if word in vocab:\n",
        "            embeddings[vocab[word]] = torch.tensor([float(x) for x in vec.split()])\n",
        "    return embeddings\n",
        "\n",
        "embeddings = load_embeddings(\"glove.6B.100d.txt\", vocab, EMBEDDING_DIM)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pretrained_RNN_model class is defined as a subclass of nn.Module and has a constructor that sets up the model architecture. The embedding_layer is defined using nn.Embedding and initialized with pre-trained embeddings. The embeddings are copied into the embedding_layer's weight tensor using the copy_ method, and the requires_grad attribute is set to freeze = False, to ensure that the weights of the embedding_layer will be updated during training. The pretrained_RNN_model constructor uses the get_directions function to determine the size of the hidden state based on whether or not the RNN is bidirectional. The get_directions function returns 2 if the RNN is bidirectional and 1 otherwise, which is used to compute the size of the hidden state in the linear layer. This ensures that the output of the RNN can be fed into the linear layer correctly, regardless of whether or not the RNN is bidirectional.\n",
        "\n",
        "* `hidden_size` is set to the product of hidden_dim and the number of directions, which is either 1 or 2 depending on the bidirectional parameter. This is because in a bidirectional RNN, the number of hidden units in the forward and backward directions are added together to obtain the total number of hidden units, whereas in a unidirectional RNN, there is only one set of hidden units.\n",
        "\n",
        "* `nn.Linear` is then defined with an input size equal to hidden_dim times the number of directions, and an output size of output_dim. This linear layer is used to map the final hidden state of the RNN to the output classes.\n",
        "\n",
        "The forward function takes in a batch of input data X_batch and passes it through the model. The input data is first passed through an embedding layer to transform it into a dense vector representation. This embedding is then fed into an RNN layer, which processes the input data sequence and produces output at each time step. The output of the RNN is concatenated and passed through a linear layer to produce the final output logits, which are then passed through a softmax function to generate class probabilities. The final probabilities are returned as the output of the forward pass.\n",
        "\n",
        "* `output_concat` is created by concatenating the last hidden_size units of the forward and backward RNN outputs. The output tensor has shape (batch_size, sequence_length, hidden_size*num_directions), so output[:, :, :self.hidden_size] selects the forward outputs and output[:, :, self.hidden_size:] selects the backward outputs.\n",
        "\n",
        "* the : in `output_concat[:, :, :]` means that we include all elements in the first two dimensions of the tensor (i.e., the batch size and the number of hidden units in the linear layer). The -1 in output_concat[:, -1, :] means that we only take the last element along the second dimension (i.e., the last hidden state of the concatenated RNN outputs).\n",
        "\n",
        "### **11.1. Unidirectional RNN model with 1 layer**\n",
        "\n",
        "An instance of the RNN_model is created and passed as an argument to setup_model function along with other hyperparameters, to set up a specific configuration of the model - in this case: unidirectional RNN model with 1 layer. The train_model function is called with the specified parameters. The time_cost variable stores the average time taken for each epoch. The evaluate_model function is called with the necessary parameters. The returned values are stored in variables for later use. The accuracies, parameters, and time_costs lists are then updated with the accuracy score, parameter count, and time cost of the model. As we'll see, these values will be stored for each model separately and will later be used to create a pretty table for comparison."
      ],
      "metadata": {
        "id": "DpbAScs3YxTV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J5AhAaAIlIN",
        "outputId": "a021e0f9-a38c-4a8a-c5ba-27f88c231bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 30.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.061\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.905\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.900\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 29.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.887\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 29.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.900\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 23.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.886\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 29.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.889\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.890\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 23.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.882\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 29.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.885\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.880\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.893\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 30.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.891\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.917\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.006\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.674\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.81      0.85      0.83      1900\n",
            "      Sports       0.79      0.98      0.88      1900\n",
            "    Business       0.50      0.86      0.64      1900\n",
            "    Sci/Tech       1.00      0.00      0.01      1900\n",
            "\n",
            "    accuracy                           0.67      7600\n",
            "   macro avg       0.78      0.67      0.59      7600\n",
            "weighted avg       0.78      0.67      0.59      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1616  150  134    0]\n",
            " [  25 1860   15    0]\n",
            " [  95  166 1639    0]\n",
            " [ 257  165 1471    7]]\n"
          ]
        }
      ],
      "source": [
        "class pretrained_RNN_model(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, bidirectional, output_dim, embeddings, freeze):\n",
        "        super(pretrained_RNN_model, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=input_dim, embedding_dim=embedding_dim)\n",
        "        self.embedding_layer.weight.data.copy_(embeddings)\n",
        "        self.embedding_layer.weight.requires_grad = freeze  # freezes the weights of the embedding layer\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
        "        self.hidden_size = hidden_dim * get_directions(bidirectional)\n",
        "        self.linear = nn.Linear(hidden_dim * get_directions(bidirectional), output_dim)\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings)\n",
        "        output_concat = torch.cat([output[:, :, :self.hidden_size], output[:, :, self.hidden_size:]], dim=2) # concatenates outputs\n",
        "        logits = self.linear(output_concat[:, -1, :]) # the last output of the concatenated RNN is used for sequence classification\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return probs\n",
        "\n",
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, False, LEARNING_RATE, embeddings, False)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1UniRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **11.2. Bidirectional RNN model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional RNN with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "4nlcAdEkbE_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9tKhkGzI1KS",
        "outputId": "3620bb0e-5a61-47b1-a874-44b0109e6358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.076\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 23.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.912\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 29.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.905\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.897\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 23.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.889\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 29.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.884\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.883\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.880\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.881\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.877\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.880\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.881\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.885\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.887\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.880\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.863\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.91      0.84      0.87      1900\n",
            "      Sports       0.91      0.97      0.94      1900\n",
            "    Business       0.86      0.76      0.81      1900\n",
            "    Sci/Tech       0.78      0.89      0.83      1900\n",
            "\n",
            "    accuracy                           0.86      7600\n",
            "   macro avg       0.87      0.86      0.86      7600\n",
            "weighted avg       0.87      0.86      0.86      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1594   91   89  126]\n",
            " [  18 1835   17   30]\n",
            " [  85   57 1439  319]\n",
            " [  55   37  119 1689]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, True, LEARNING_RATE, embeddings, False)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1BiRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **11.3. Bidirectional RNN model with 2 layers**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional RNN with two layers. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "B3z28_HObS7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIXnc8_ZbyZS",
        "outputId": "b22f72dd-6297-44ae-dce8-4ce9bed7a650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.013\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.917\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.904\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.926\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.906\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.894\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.928\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.937\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.897\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.886\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.888\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.888\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.911\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.887\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.881\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.864\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.90      0.86      0.88      1900\n",
            "      Sports       0.91      0.96      0.94      1900\n",
            "    Business       0.80      0.83      0.82      1900\n",
            "    Sci/Tech       0.85      0.80      0.82      1900\n",
            "\n",
            "    accuracy                           0.86      7600\n",
            "   macro avg       0.86      0.86      0.86      7600\n",
            "weighted avg       0.86      0.86      0.86      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1634   90  120   56]\n",
            " [  18 1828   27   27]\n",
            " [  84   46 1586  184]\n",
            " [  83   43  257 1517]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 2, True, LEARNING_RATE, embeddings, False)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_2BiRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pretrained_LSTM_model class is defined as a subclass of nn.Module and has a constructor that sets up the model architecture. The embedding_layer is defined using nn.Embedding and initialized with pre-trained embeddings. The embeddings are copied into the embedding_layer's weight tensor using the copy_ method, and the requires_grad attribute is set to freeze = False, to ensure that the weights of the embedding_layer will be updated during training. The pretrained_LSTM_model constructor uses the get_directions function to determine the size of the hidden state based on whether or not the LSTM is bidirectional. The get_directions function returns 2 if the LSTM is bidirectional and 1 otherwise, which is used to compute the size of the hidden state in the linear layer. This ensures that the output of the LSTM can be fed into the linear layer correctly, regardless of whether or not the LSTM is bidirectional.\n",
        "\n",
        "* `hidden_size` is set to the product of hidden_dim and the number of directions, which is either 1 or 2 depending on the bidirectional parameter. This is because in a bidirectional LSTM, the number of hidden units in the forward and backward directions are added together to obtain the total number of hidden units, whereas in a unidirectional LSTM, there is only one set of hidden units.\n",
        "\n",
        "* `nn.Linear` is then defined with an input size equal to hidden_dim times the number of directions, and an output size of output_dim. This linear layer is used to map the final hidden state of the LSTM to the output classes.\n",
        "\n",
        "The forward function takes in a batch of input data X_batch and passes it through the model. The input data is first passed through an embedding layer to transform it into a dense vector representation. This embedding is then fed into an LSTM layer, which processes the input data sequence, produces the output at each time step and updates the hidden and cell state. The output of the LSTM is concatenated and passed through a linear layer to produce the final output logits, which are then passed through a softmax function to generate class probabilities. The final probabilities are returned as the output of the forward pass.\n",
        "\n",
        "* `output_concat` is created by concatenating the last hidden_size units of the forward and backward LSTM outputs. The output tensor has shape (batch_size, sequence_length, hidden_size*num_directions), so output[:, :, :self.hidden_size] selects the forward outputs and output[:, :, self.hidden_size:] selects the backward outputs.\n",
        "\n",
        "* the : in `output_concat[:, :, :]` means that we include all elements in the first two dimensions of the tensor (i.e., the batch size and the number of hidden units in the linear layer). The -1 in output_concat[:, -1, :] means that we only take the last element along the second dimension (i.e., the last hidden state of the concatenated LSTM outputs).\n",
        "\n",
        "### **11.4. Unidirectional LSTM model with 1 layer**\n",
        "\n",
        "An instance of the pretrained_LSTM_model is created and passed as an argument to setup_model function along with other hyperparameters, to set up a specific configuration of the model - in this case: unidirectional LSTM model with 1 layer. The train_model function is called with the specified parameters. The time_cost variable stores the average time taken for each epoch. The evaluate_model function is called with the necessary parameters. The returned values are stored in variables for later use. The accuracies, parameters, and time_costs lists are then updated with the accuracy score, parameter count, and time cost of the model. As we'll see, these values will be stored for each model separately and will later be used to create a pretty table for comparison."
      ],
      "metadata": {
        "id": "2q5iLxFubeWm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuAjQTnfbzcP",
        "outputId": "ee462c68-e24a-40e8-a391-7ed9d69db3eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.029\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.874\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.864\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.858\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.855\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.852\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.848\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.846\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.844\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.841\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.840\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.838\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.836\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.835\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.834\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.893\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.88      0.90      0.89      1900\n",
            "      Sports       0.95      0.96      0.96      1900\n",
            "    Business       0.90      0.81      0.85      1900\n",
            "    Sci/Tech       0.84      0.90      0.87      1900\n",
            "\n",
            "    accuracy                           0.89      7600\n",
            "   macro avg       0.89      0.89      0.89      7600\n",
            "weighted avg       0.89      0.89      0.89      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1716   58   68   58]\n",
            " [  39 1825   19   17]\n",
            " [  98   17 1532  253]\n",
            " [  86   13   89 1712]]\n"
          ]
        }
      ],
      "source": [
        "class pretrained_LSTM_model(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, bidirectional, output_dim, embeddings, freeze):\n",
        "        super(pretrained_LSTM_model, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=input_dim, embedding_dim=embedding_dim)\n",
        "        self.embedding_layer.weight.data.copy_(embeddings)\n",
        "        self.embedding_layer.weight.requires_grad = freeze  # freezes the weights of the embedding layer\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
        "        self.hidden_size = hidden_dim * get_directions(bidirectional)\n",
        "        self.linear = nn.Linear(hidden_dim * get_directions(bidirectional), output_dim)\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, (hidden, cell) = self.lstm(embeddings)\n",
        "        output_concat = torch.cat([output[:, :, :self.hidden_size], output[:, :, self.hidden_size:]], dim=2) # concatenates outputs\n",
        "        logits = self.linear(output_concat[:, -1, :]) # the last output of the concatenated LSTM is used for sequence classification\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return probs\n",
        "\n",
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, False, LEARNING_RATE, embeddings, False)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1UniLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **11.5. Bidirectional LSTM model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional LSTM with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "Pvq4dOJehElE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3r85qgZb3x2",
        "outputId": "621ec336-79c2-4217-8d6f-4a8b17e48d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.034\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.873\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.863\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.857\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.854\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.850\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.848\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.845\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.842\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.841\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.840\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.837\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.836\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.833\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.832\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.899\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.92      0.88      0.90      1900\n",
            "      Sports       0.95      0.97      0.96      1900\n",
            "    Business       0.86      0.86      0.86      1900\n",
            "    Sci/Tech       0.86      0.89      0.87      1900\n",
            "\n",
            "    accuracy                           0.90      7600\n",
            "   macro avg       0.90      0.90      0.90      7600\n",
            "weighted avg       0.90      0.90      0.90      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1678   62   94   66]\n",
            " [  25 1837   19   19]\n",
            " [  65   18 1631  186]\n",
            " [  51   11  153 1685]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, True, LEARNING_RATE, embeddings, False)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1BiLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **11.6. Bidirectional LSTM model with 2 layers**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional LSTM with two layers. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "ar2AAqDwhW7O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6tfLEBsb5Cn",
        "outputId": "737db8ed-6608-4ac5-ca27-0655f56c2094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 23.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.011\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.873\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.868\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.860\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.855\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.851\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.849\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.846\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.844\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.843\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.840\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.839\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.838\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.835\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.835\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.898\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.88      0.91      0.90      1900\n",
            "      Sports       0.95      0.97      0.96      1900\n",
            "    Business       0.87      0.85      0.86      1900\n",
            "    Sci/Tech       0.88      0.86      0.87      1900\n",
            "\n",
            "    accuracy                           0.90      7600\n",
            "   macro avg       0.90      0.90      0.90      7600\n",
            "weighted avg       0.90      0.90      0.90      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1727   62   67   44]\n",
            " [  25 1843   20   12]\n",
            " [ 103   18 1614  165]\n",
            " [  97   13  149 1641]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 2, True, LEARNING_RATE, embeddings, False)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_2BiLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **12. Visualize the performance metrics of the models**\n",
        "\n",
        "The visualize function is called to generate and display tables that compare the performance of all the models trained above."
      ],
      "metadata": {
        "id": "J2F7rY0rhluX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2Axb3sGcBLO",
        "outputId": "18523df4-4243-4a61-be5a-231dc02bd593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+------------+-----------+\n",
            "|    \u001b[1mModel\u001b[0m     | \u001b[1mAccuracy\u001b[0m | \u001b[1mParameters\u001b[0m | \u001b[1mTime Cost\u001b[0m |\n",
            "+--------------+----------+------------+-----------+\n",
            "| 1Uni-preRNN  |  0.6739  |   10884    |   4.3174  |\n",
            "|  1Bi-preRNN  |  0.8628  |   21764    |   4.4582  |\n",
            "|  2Bi-preRNN  |  0.8638  |   46596    |   4.757   |\n",
            "| 1Uni-preLSTM |  0.8928  |   42756    |   4.6302  |\n",
            "| 1Bi-preLSTM  |  0.8988  |   85508    |   4.9775  |\n",
            "| 2Bi-preLSTM  |  0.898   |   184836   |   5.1593  |\n",
            "+--------------+----------+------------+-----------+\n"
          ]
        }
      ],
      "source": [
        "visualize(models, accuracies, parameters, time_costs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`##########################`"
      ],
      "metadata": {
        "id": "BNJfQBSthzNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **13. RNN & LSTM models trained on AGNTC dataset with sequence length of 25 words and frozen pre-trained word embeddings (glove-6B100d)**\n",
        "\n",
        "This is a variation of the previous implementation (see: Unit 11) that incorporates frozen pre-trained word embeddings (glove-6B100d). We basically freeze the embeddings layer, so that its weights don't get updated during training (the pre-trained word embeddings are used as fixed features in the model)."
      ],
      "metadata": {
        "id": "SzJ1DU2dh3dU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "81cVjb6_oELE"
      },
      "outputs": [],
      "source": [
        "accuracies = []; parameters = []; time_costs = []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **13.1. Unidirectional RNN model with 1 layer**\n",
        "\n",
        "An instance of the RNN_model is created and passed as an argument to setup_model function along with other hyperparameters, to set up a specific configuration of the model - in this case: unidirectional RNN model with 1 layer. The train_model function is called with the specified parameters. The time_cost variable stores the average time taken for each epoch. The evaluate_model function is called with the necessary parameters. The returned values are stored in variables for later use. The accuracies, parameters, and time_costs lists are then updated with the accuracy score, parameter count, and time cost of the model. As we'll see, these values will be stored for each model separately and will later be used to create a pretty table for comparison."
      ],
      "metadata": {
        "id": "1Yxbv77Kj9cA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMz3A_uncE62",
        "outputId": "0c1cf898-1d63-4829-f05e-656e65276d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.088\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.892\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.892\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.865\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.859\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.855\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.851\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.853\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.845\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.854\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 27.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.865\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.911\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 28.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.848\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.862\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.849\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.879\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.90      0.87      0.89      1900\n",
            "      Sports       0.94      0.95      0.95      1900\n",
            "    Business       0.86      0.81      0.83      1900\n",
            "    Sci/Tech       0.81      0.89      0.85      1900\n",
            "\n",
            "    accuracy                           0.88      7600\n",
            "   macro avg       0.88      0.88      0.88      7600\n",
            "weighted avg       0.88      0.88      0.88      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1657   55   87  101]\n",
            " [  48 1802   15   35]\n",
            " [  82   34 1532  252]\n",
            " [  57   16  138 1689]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, False, LEARNING_RATE, embeddings, True)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1UniRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **13.2. Bidirectional RNN model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional RNN with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "j2phYz1ekOs0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfxHL8sqnskl",
        "outputId": "8d81f3d7-731c-4226-d30b-c1da060fd36e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.101\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.912\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.882\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.872\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.872\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.856\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 23.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.853\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.853\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.848\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.848\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.843\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 23.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.842\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 23.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.839\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 26.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.839\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.838\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.889\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.92      0.88      0.90      1900\n",
            "      Sports       0.94      0.96      0.95      1900\n",
            "    Business       0.87      0.81      0.84      1900\n",
            "    Sci/Tech       0.83      0.90      0.86      1900\n",
            "\n",
            "    accuracy                           0.89      7600\n",
            "   macro avg       0.89      0.89      0.89      7600\n",
            "weighted avg       0.89      0.89      0.89      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1673   66   91   70]\n",
            " [  16 1832   14   38]\n",
            " [  87   26 1543  244]\n",
            " [  49   19  124 1708]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, True, LEARNING_RATE, embeddings, True)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1BiRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **13.3. Bidirectional RNN model with 2 layers**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional RNN with two layers. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "cksI7PbMkese"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ex0PZTZnugO",
        "outputId": "23090902-f674-487e-ecaa-635969e0beb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 23.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.001\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.899\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 22.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.873\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 23.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.858\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.852\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.848\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 19.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.846\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.848\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.871\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 23.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.863\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.840\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.845\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 23.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.843\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.844\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.843\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.889\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.95      0.85      0.90      1900\n",
            "      Sports       0.92      0.97      0.95      1900\n",
            "    Business       0.86      0.82      0.84      1900\n",
            "    Sci/Tech       0.83      0.90      0.87      1900\n",
            "\n",
            "    accuracy                           0.89      7600\n",
            "   macro avg       0.89      0.89      0.89      7600\n",
            "weighted avg       0.89      0.89      0.89      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1621   83  128   68]\n",
            " [  12 1850   17   21]\n",
            " [  41   39 1566  254]\n",
            " [  35   33  116 1716]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 2, True, LEARNING_RATE, embeddings, True)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_2BiRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **13.4. Unidirectional LSTM model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a unidirectional LSTM with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "oz7SEfxOkpbl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm8jL4NBnwQT",
        "outputId": "5163e892-9fa2-4586-ca48-acec1938839f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.019\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.857\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.841\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.831\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.823\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.818\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.813\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.809\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 23.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.807\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.805\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.804\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 25.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.801\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.800\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 24.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.799\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:04<00:00, 23.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.798\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.908\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.92      0.91      0.91      1900\n",
            "      Sports       0.96      0.97      0.96      1900\n",
            "    Business       0.88      0.87      0.87      1900\n",
            "    Sci/Tech       0.88      0.89      0.88      1900\n",
            "\n",
            "    accuracy                           0.91      7600\n",
            "   macro avg       0.91      0.91      0.91      7600\n",
            "weighted avg       0.91      0.91      0.91      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1727   52   74   47]\n",
            " [  24 1845   17   14]\n",
            " [  64   16 1650  170]\n",
            " [  70   11  137 1682]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, False, LEARNING_RATE, embeddings, True)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1UniLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **13.5. Bidirectional LSTM model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional LSTM with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "Kz716Gu5k249"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E90rAICnnxln",
        "outputId": "db6c83bd-95d5-422a-ea1b-a054cc86377f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 19.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 1.046\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.860\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.841\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 20.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.831\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.823\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.818\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.813\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.810\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.807\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.805\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.803\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.802\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.801\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:05<00:00, 21.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.799\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.798\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.908\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.92      0.91      0.91      1900\n",
            "      Sports       0.95      0.97      0.96      1900\n",
            "    Business       0.88      0.86      0.87      1900\n",
            "    Sci/Tech       0.88      0.89      0.88      1900\n",
            "\n",
            "    accuracy                           0.91      7600\n",
            "   macro avg       0.91      0.91      0.91      7600\n",
            "weighted avg       0.91      0.91      0.91      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1720   56   74   50]\n",
            " [  19 1846   16   19]\n",
            " [  70   19 1641  170]\n",
            " [  66   14  128 1692]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, True, LEARNING_RATE, embeddings, True)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1BiLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **13.6. Bidirectional LSTM model with 2 layers**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional LSTM with two layers. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "R9iDLNlPlEsE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHHxnoO7nyvM",
        "outputId": "ac79ab4f-84e6-4b60-de3e-b8ab7ab8fed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.987\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.855\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.842\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.833\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.827\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 17.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.821\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.818\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.814\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.811\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.809\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.806\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.805\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 16.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.803\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 16.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.803\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:06<00:00, 18.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.800\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.908\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       World       0.92      0.90      0.91      1900\n",
            "      Sports       0.94      0.98      0.96      1900\n",
            "    Business       0.88      0.86      0.87      1900\n",
            "    Sci/Tech       0.88      0.88      0.88      1900\n",
            "\n",
            "    accuracy                           0.91      7600\n",
            "   macro avg       0.91      0.91      0.91      7600\n",
            "weighted avg       0.91      0.91      0.91      7600\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[1714   67   71   48]\n",
            " [  14 1862   12   12]\n",
            " [  74   24 1643  159]\n",
            " [  64   20  135 1681]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, pretrained_LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 2, True, LEARNING_RATE, embeddings, True)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_2BiLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **14. Visualize the performance metrics of the models**\n",
        "\n",
        "The visualize function is called to generate and display tables that compare the performance of all the models trained above."
      ],
      "metadata": {
        "id": "RdbJ7pMblZaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5bRajBAn0Lb",
        "outputId": "685efca3-9e33-40a4-9718-78664dd513bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+------------+-----------+\n",
            "|    \u001b[1mModel\u001b[0m     | \u001b[1mAccuracy\u001b[0m | \u001b[1mParameters\u001b[0m | \u001b[1mTime Cost\u001b[0m |\n",
            "+--------------+----------+------------+-----------+\n",
            "| 1Uni-preRNN  |  0.8789  |  2136284   |   4.6362  |\n",
            "|  1Bi-preRNN  |  0.8889  |  2147164   |   4.8546  |\n",
            "|  2Bi-preRNN  |  0.8886  |  2171996   |   5.3012  |\n",
            "| 1Uni-preLSTM |  0.9084  |  2168156   |   5.1848  |\n",
            "| 1Bi-preLSTM  |  0.9078  |  2210908   |   5.9696  |\n",
            "| 2Bi-preLSTM  |  0.9079  |  2310236   |   6.8009  |\n",
            "+--------------+----------+------------+-----------+\n"
          ]
        }
      ],
      "source": [
        "visualize(models, accuracies, parameters, time_costs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`##########################################################`"
      ],
      "metadata": {
        "id": "FeYeqJidlcj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **15. RNN & LSTM models trained on IMDB dataset with sequence length of 25 words**\n",
        "\n",
        "This is a variation of the very first implementation (see: Unit 6), where the dataset is now the IMDB instead of the AGNTC dataset. The classes list specifies the different categories or classes that the classification models will be trained to predict. In this case, we have two classes: Positive and Negative. This suggest that our models will be trained to classify movie reviews into these two broad categories. We load the IMDB Dataset from a CSV file and create two datasets - train_dataset and test_dataset. The first contains 80% of the data and will be used for training, while the latter contains the remaining 20% of the data and will be used for evaluating the models' performance."
      ],
      "metadata": {
        "id": "KgjUMbJHlfu-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "0weqTUexpewP"
      },
      "outputs": [],
      "source": [
        "models = [\"1Uni-RNN\", \"1Bi-RNN\", \"2Bi-RNN\", \"1Uni-LSTM\", \"1Bi-LSTM\", \"2Bi-LSTM\"]; classes = [\"Positive\", \"Negative\"]; accuracies = []; parameters = []; time_costs = []\n",
        "train_dataset, test_dataset = load_dataset(\"IMDB Dataset.csv\", [\"review\"], \"sentiment\", 80, \"start\"), load_dataset(\"IMDB Dataset.csv\", [\"review\"], \"sentiment\", 20, \"end\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The replace_labels function takes in a dataset along with two lists: categorical and numerical, which represent the current labels in the dataset and their corresponding numerical values. The function replaces the categorical labels with their corresponding numerical values and returns a new dataset with the updated labels. The train_dataset and test_dataset are then assigned to the new datasets returned by the replace_labels function."
      ],
      "metadata": {
        "id": "A9WpjX1RqHtu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9ci7Rp2qqCXb"
      },
      "outputs": [],
      "source": [
        "def replace_labels(dataset, categorical, numerical):\n",
        "    mapping = {categorical[0]: numerical[0], categorical[1]: numerical[1]}\n",
        "    return [(mapping[label], text) for label, text in dataset]\n",
        "\n",
        "train_dataset, test_dataset = replace_labels(train_dataset, [\"negative\", \"positive\"], [1,2]), replace_labels(test_dataset, [\"negative\", \"positive\"], [1,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data loaders for the training and testing datasets are generated, using the generate_loader function, and the vocabulary is built using the build_vocab function - just like we did in the very first implementation."
      ],
      "metadata": {
        "id": "g4y2yCANqdvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sqH7Myk2qHBc"
      },
      "outputs": [],
      "source": [
        "train_loader, test_loader = generate_loader(train_dataset, MAX_WORDS, BATCH_SIZE, True), generate_loader(test_dataset, MAX_WORDS, BATCH_SIZE, False)\n",
        "vocab = build_vocab([train_dataset, test_dataset], MIN_FREQ, PADDED, UNKNOWN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **15.1. Unidirectional RNN model with 1 layer**\n",
        "\n",
        "An instance of the RNN_model is created and passed as an argument to setup_model function along with other hyperparameters, to set up a specific configuration of the model - in this case: unidirectional RNN model with 1 layer. The train_model function is called with the specified parameters. The time_cost variable stores the average time taken for each epoch. The evaluate_model function is called with the necessary parameters. The returned values are stored in variables for later use. The accuracies, parameters, and time_costs lists are then updated with the accuracy score, parameter count, and time cost of the model. As we'll see, these values will be stored for each model separately and will later be used to create a pretty table for comparison."
      ],
      "metadata": {
        "id": "0qInAoWPrc2O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH2plC5bqQAF",
        "outputId": "e8bec6a8-d576-4e2e-ac3e-f78d62c14337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.694\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.688\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.668\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.642\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.612\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.590\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.567\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.546\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.532\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.516\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.507\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.494\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.482\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.475\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.469\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.825\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.84      0.79      0.82      4954\n",
            "    Negative       0.81      0.85      0.83      5046\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.83      0.82      0.82     10000\n",
            "weighted avg       0.83      0.82      0.82     10000\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[3938 1016]\n",
            " [ 738 4308]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, False, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1UniRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **15.2. Bidirectional RNN model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional RNN with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "aZ86NrNlrjOk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a7pOcyXqYyj",
        "outputId": "2bbd6060-7efd-4d8d-b1d3-1b8cec003b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.695\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.687\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.663\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.632\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.603\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.580\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.560\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.540\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.527\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.510\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.496\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.491\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.479\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.473\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.465\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.828\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.82      0.83      0.83      4954\n",
            "    Negative       0.83      0.83      0.83      5046\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[4106  848]\n",
            " [ 877 4169]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1BiRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **15.3. Bidirectional RNN model with 2 layers**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional RNN with two layers. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "2W3mLgMErwbm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVCDnakhqafD",
        "outputId": "d11cd5cb-a9e8-44b4-a910-b93db874e47d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.693\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.674\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.651\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.629\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.602\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.581\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.566\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.539\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.525\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.513\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.497\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.484\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.473\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.474\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.462\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.828\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.83      0.83      0.83      4954\n",
            "    Negative       0.83      0.83      0.83      5046\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[4089  865]\n",
            " [ 853 4193]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, RNN_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 2, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_2BiRNN = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **15.4. Unidirectional LSTM model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a unidirectional LSTM with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "okJ_1k0Sr3Bd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8h2Gwcoqb3t",
        "outputId": "8ffe22c8-71d6-4675-ae9f-3c50a7e0e237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.692\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.675\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.626\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.588\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.559\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.539\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.519\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.498\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.486\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.473\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.459\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.450\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.448\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.431\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.426\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.862\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.86      0.87      0.86      4954\n",
            "    Negative       0.87      0.86      0.86      5046\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[4288  666]\n",
            " [ 715 4331]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, False, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1UniLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **15.5. Bidirectional LSTM model with 1 layer**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional LSTM with one layer. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "Bl6WoTB3sGae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5TjwnI6qdJH",
        "outputId": "9febbc12-70f5-4107-a40c-636cbed2f400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.693\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.681\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.639\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.598\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.565\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.539\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.519\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.505\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.486\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.472\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.462\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.451\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.443\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.436\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:06<00:00,  5.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.431\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.839\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.88      0.79      0.83      4954\n",
            "    Negative       0.81      0.89      0.85      5046\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[3899 1055]\n",
            " [ 553 4493]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 1, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_1BiLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **15.6. Bidirectional LSTM model with 2 layers**\n",
        "\n",
        "We now apply the same procedure to another model, specifically a bidirectional LSTM with two layers. We set up the model using the setup_model() function, train it using the train_model() function, evaluate it using the evaluate_model() function, and then store the accuracy, number of parameters, and time cost for the trained model in the corresponding lists."
      ],
      "metadata": {
        "id": "Ma9IEdWJsNwA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oacXOs7nqePr",
        "outputId": "df533df5-0b73-4e0a-fef1-ceb279dff501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mEpoch\u001b[0m: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:08<00:00,  4.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.688\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:08<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.651\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.604\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:08<00:00,  4.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.570\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.545\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.523\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:08<00:00,  5.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.506\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.489\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:08<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.475\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:08<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.470\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.457\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:08<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.445\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.437\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.430\n",
            "\n",
            "\u001b[1mEpoch\u001b[0m: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:07<00:00,  5.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTrain Loss\u001b[0m: 0.427\n",
            "\n",
            "\u001b[1mTest Accuracy\u001b[0m: 0.861\n",
            "\n",
            "\u001b[1mClassification Report:\u001b[0m\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.85      0.87      0.86      4954\n",
            "    Negative       0.87      0.85      0.86      5046\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\u001b[1mConfusion Matrix:\u001b[0m\n",
            " [[4300  654]\n",
            " [ 737 4309]]\n"
          ]
        }
      ],
      "source": [
        "classifier, loss_fn, optimizer = setup_model(device, LSTM_model, classes, vocab, EMBEDDING_DIM, HIDDEN_DIM, 2, True, LEARNING_RATE, None, None)\n",
        "time_cost = train_model(classifier, loss_fn, optimizer, train_loader, EPOCHS)\n",
        "_, Y_actual, Y_preds, misclass_data_2BiLSTM = evaluate_model(classes, classifier, loss_fn, test_loader, to_dict(test_dataset))\n",
        "accuracies.append(accuracy_score(Y_actual, Y_preds))\n",
        "parameters.append(count_parameters(classifier))\n",
        "time_costs.append(time_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **16. Visualize the performance metrics of the models**\n",
        "\n",
        "The visualize function is called to generate and display tables that compare the performance of all the models trained above."
      ],
      "metadata": {
        "id": "VjI7DfFvser2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnf3hB1-qfe1",
        "outputId": "a33b315e-40d5-455f-a56d-9516f00a3777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+------------+-----------+\n",
            "|   \u001b[1mModel\u001b[0m   | \u001b[1mAccuracy\u001b[0m | \u001b[1mParameters\u001b[0m | \u001b[1mTime Cost\u001b[0m |\n",
            "+-----------+----------+------------+-----------+\n",
            "|  1Uni-RNN |  0.8246  |  2929754   |   6.7313  |\n",
            "|  1Bi-RNN  |  0.8275  |  2940506   |   6.9442  |\n",
            "|  2Bi-RNN  |  0.8282  |  2965338   |   7.033   |\n",
            "| 1Uni-LSTM |  0.8619  |  2961626   |   7.0056  |\n",
            "|  1Bi-LSTM |  0.8392  |  3004250   |   7.2695  |\n",
            "|  2Bi-LSTM |  0.8609  |  3103578   |   7.7724  |\n",
            "+-----------+----------+------------+-----------+\n"
          ]
        }
      ],
      "source": [
        "visualize(models, accuracies, parameters, time_costs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`############################`"
      ],
      "metadata": {
        "id": "LY-oMa_YshS2"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSCmgueC0pvvO+yazUvN/u",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}